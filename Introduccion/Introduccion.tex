%---------------------------------------------------------------------
%
%                         Introduccion
%---------------------------------------------------------------------

\chapter{Introducción}
%mirar problema con fancyheader y secciones no numeradas, pagina 21-22 del manual
\fancyhead[RO,LE]{\sc{Introducción}}

%\fancyfoot[C]{\small \thepage }

%\addcontentsline{toc}{chapter}{Introducción}
%\cabeceraEspecial{Introducción}

\addcontentsline{lof}{chapter}{Introducción}



%~ \begin{FraseCelebre}
%~ \begin{Frase}
 %~ I spend a lot of time on this task. I should write a program automating it!
%~ \end{Frase}
%~ \begin{Fuente}
%~ Randall Munroe, xkcd
%~ \end{Fuente}
%~ \end{FraseCelebre}

%~ \begin{resumen}
%~ \begin{figure}[H]
%~ \begin{center}
%~ \hfill
%~ \includegraphics[width=0.7\textwidth]{Imagenes/Vectorial/automation}
%~ 
%~ \end{center}
%~ \end{figure}
%~ \end{resumen}


%~ \begin{resumen}
%~ Tradicionalmente, el gen se ha concebido como la unidad fundamental -el átomo- de la
 %~ vida, sometida a la acción de la selección natural. Así definió Richard
 %~ Dawkins en el Gen Egoísta al gen, la unidad indivisible auto-replicante,
 %~ mientras que 
 %~ los individuos y sus conductas eran meras \textit{máquinas de supervivencia}. 
 %~ Sin embargo, es el fenotipo y no el genotipo lo que interactúa con el
 %~ ambiente y con otros organismos. Las proteínas, los \textit{ladrillos} 
 %~ con que se construye la vida, sí son visibles, a diferencia de los genes,
 %~ a la selección natural.
 %~ Por otra parte, el clásico dogma central de la Biología Molecular \textit{un gen, una proteína}
 %~ caducó hace ya tiempo y hoy lo recordamos, más bien, como una simplificación excesiva.
 %~ Actualmente, el emergente campo de la Proteogenómica da cuenta de la intrincada 
 %~ red de procesos regulatorios de transferencia de información entre el gen y la proteína.
 %~ La proteómica por su parte, le debe a la Genómica el reconocimiento y agradecimiento
 %~ de haber abierto camino en la Biotecnología moderna. 
 %~ La Bioinformática, en este panorama, tiene un papel integrador. Al igual
 %~ que la proteómica, se sirve de diferentes tecnologías que avanzan y se
 %~ retroalimentan sinérgicamente. Así la proteómica se beneficia de los
 %~ avances en Espectrometría de Masas, y estos instrumentos progresan en 
 %~ función de la demanda en investigación. De la misma manera, la
 %~ proteómica Computacional, la parte de la Bioinformática mas cercana a
 %~ la proteómica, evoluciona para facilitar el análisis de los datos que
 %~ los investigadores requieren, pero también se beneficia de la incesante y
 %~ creciente capacidad de procesamiento en las computadoras actuales.  
%~ 
%~ \end{resumen}

%\newpage

%---------------------------------------------------------------------
%---------------------------------------------------------------------


\setcounter{chapter}{1}
%-------------------------------------------------------------------
%\phantomsection %Note that if you use PDF bookmarks you will need to 
%add a phantom section so that bookmark will lead to the correct place in the document
\section{Proteómica. Conceptos generales} % * hace que la seccion no esté numerada. Esta sería 0.1
%\addcontentsline{toc}{section}{Proteómica. Conceptos generales}
%-------------------------------------------------------------------
\label{cap1:sec:Proteómica. Conceptos generales}

El concepto de proteoma fue acuñado originalmente por Marc Wilkins en 
los años 90 en analogía al concepto de Genoma \citep{Wasinger1995}.
Si el genoma es la dotación génica de una célula u organismo, 
el proteoma es entendido como \emph{el conjunto total de proteínas 
expresadas por los genes de una célula, tejido u organismo}. 
Sin embargo, mientras que el Genoma es el mismo en todas las 
células del organismo, el proteoma es un concepto más variable. 
Los genes se expresan en función de las condiciones en que se encuentra
la célula, según el orgánulo, el tejido, y
estadío del desarrollo entre otros factores. Además existen niveles de complejidad
adicional en el curso de información desde el gen a la proteína 
como el procesamiento alternativo de intrones y las modificaciones post-traduccionales \ac{PTM}.
Por eso el término \emph{proteoma} puede diversificarse, para ajustarse a definiciones mas específicas.
Así, podemos hablar del proteoma (o fosfo-proteoma, por ejemplo) de un orgánulo
celular, como la mitocondria, en un tejido concreto, en unas condiciones
ambientales definidas por los nutrientes disponibles, posiblemente sometida a
 condiciones de estrés, \textit{etc}.

Proteómica es, por tanto, el estudio del proteoma, independientemente
del conjunto o subconjunto de proteínas objeto de estudio. 
Pero además, el término \emph{proteómica} se refiere a las tecnologías utilizadas para ello.

El establecimiento de la espectrometría de masas aplicada a moléculas
biológicas a finales de los años 80 y el desarrollo de técnicas de 
separación de proteínas y péptidos como la electroforesis
\ac{PAGE} y la cromatografía  \ac{HPLC}
 permitieron que la proteómica se 
consolidara y extendiera como disciplina científica.

La figura~\ref{fig:proteome_complexity} ilustra como el grado de complejidad 
biológica desde la unidad de información, es decir, el gen, hasta la
 unidad funcional, la proteína, aumenta exponencialmente. 

\figura{Vectorial/proteome_complexity}{width=.99\textwidth}{fig:proteome_complexity}%
{Aumento de complejidad desde el genoma hacia el proteoma}



%---------------------------------------------------------------------
%---------------------------------------------------------------------

%-------------------------------------------------------------------
%\phantomsection %Note that if you use PDF bookmarks you will need to 
%add a phantom section so that bookmark will lead to the correct place in the document
\section{Espectrometría de masas}
%\addcontentsline{toc}{section}{Espectrometría de masas}
%-------------------------------------------------------------------
\label{cap1:sec:Espectrometría de masas}
El desarrollo, a finales de los años 70 del siglo pasado, de las técnicas de ionización suave 
como la desorción \ac{FD}, la desorción \ac{PD} y la ionización \ac{FAB} permitió por primera vez que las
grandes y lábiles moléculas biológicas como péptidos y proteínas pudieran ser ionizadas y 
volatilizadas relativamente intactas para ser a continuación introducidas en los espectrómetros
de masas.
Posteriormente, a finales de los 80, el desarrollo de la ionización \ac{ESI} \citep{Fenn1989a}
y \ac{SLD} \citep{Tanaka1988}, además de valer el premio Nobel a los químicos John Fenn y Koichi Tanaka, 
permitió sentar definitivamente las bases de la espectrometría de masas aplicada a la 
proteómica. 
 


 Como ocurre en muchas otras ocasiones en la ciencia, de forma paralela e
independientemente habían surgido en distintas partes del mundo ideas
muy similares. Así, el desarrollo de \ac{SLD} que valió el Nobel a K. Tanaka,
tuvo un precedente unos años antes.
Franz Hillenkamp y Michael Karas en Frankfurt, Alemania (éstos 
discutiblemente no galardonados) habían ideado una técnica similar que,
en este caso, denominaron \ac{MALDI} 
\citep{Karas1988}. Aunque la ionización \ac{MALDI} no fue aplicada a 
proteínas hasta la publicación del trabajo de Tanaka, actualmente 
éste es el acrónimo que se ha impuesto para referirse a la técnica y es,
de hecho, una técnica muy extendida en laboratorios de espectrometría de masas.

%---------------------------------------------------------------------
%---------------------------------------------------------------------

\subsection{Consideraciones sobre unidades empleadas en espectrometría de masas}
%\addcontentsline{toc}{subsection}{Unidades empleadas en espectrometría de masas}

La unidad fundamental de masa usada en física y química, empleada en la
medida de masas atómicas y moleculares, es la llamada \textit{Unidad de Masa Atómica}, \textbf{u}, o \textbf{uma}
también denominada \textit{Dalton}, \textbf{Da}. 
La escala de unidades de masa atómica es una escala relativa donde la referencia es el átomo de carbono.
El valor de una \emph{u} o un \emph{Dalton} se define como la doceava parte
de la masa de un átomo neutro de \textsuperscript{12}C, el isótopo más frecuente de carbono.
Así, la masa de un átomo de  \textsuperscript{12}C es de 12 u. Y una \emph{u} es aproximadamente
equivalente a la masa de un átomo de hidrógeno o la masa de un protón.

\begin{equation}
\label{eq:uma_definition}
\begin{split}
1 Da &= 1 u = 1/12 \cdot \left(\frac{12g\ \ce{^{12}C}}{mol\ \ce{^{12}C}}\right)\\
\textup{}\\
1 Da &= 1 u = 1/12 \cdot \left(\frac{6.0221\times10^{23} \acute atomos \ce{^{12}C}}{mol\ \ce{^{12}C}}\right)\\
\textup{}\\
1 Da &= 1 u = 1.66054\times10^{-24}g/ \acute atomo\ \ce{^{12}C} = 1.66054\times10^{-27}kg/ \acute atomo\ \ce{^{12}C}
\end{split}
\end{equation}

\medskip

Sin embargo los analizadores de masas no miden la masa 
de los analitos ionizados sino la relación entre masa y carga \mz , donde
\emph{m} es la masa molecular del analito y \emph{z} un múltiplo entero del número de 
cargas del ion. La unidad empleada para medir esta relación es el \textit{Thomson},
\textbf{Th}. Un thomson equivale a 1 Da / e, donde e es la carga elemental.
En general, para iones monocargados y solo en ese caso, la masa en Da
es equivalente a su valor en thomsons.

Además, en espectrometría de masas es interesante medir la masa exacta de los isótopos
de los elementos que componen las moléculas. En este sentido es importante
diferenciar entre las masas mono-isotópica y masa promedio.

La \emph{masa promedio} es equivalente a una media de las masas atómicas de todos
los átomos de los elementos que componen el ion ponderados por abundancia
isotópica.
Mientras que la \emph{masa mono-isotópica} es aquella en la que se 
considera que todos los átomos de C se encuentran en su forma \textsuperscript{12}C.


%---------------------------------------------------------------------
%---------------------------------------------------------------------


%\medskip %Produces a medium-sized space between paragraphs.
\subsection{Espectrómetro de masas}
%\addcontentsline{toc}{subsection}{Componentes de un espectrómetro de masas}

Un espectrómetro de masas es, en esencia, una balanza de precisión molecular capaz
de medir, hasta un determinado límite de sensiblidad, la masa (en relación a la carga)
de moléculas (ionizadas). Consta básicamente de cuatro partes o secciones:

\bigskip

\figuraEx{Vectorial/esquema_espectrometro_masas}{width=.99\textwidth}{fig:esquema_espectrometro_masas}%
{Esquema de un espectrómetro de masas. En ocasiones el caso de ESI, el sistema de entrada y la fuente 
de ionización forman parte de un único componente. Todos los componentes se encuentran
en el interior de un sistema de vacío }{Esquema de un espectrómetro de masas}



\begin{enumerate}

\item \textbf{Sistema de entrada}. Generalmente los espectrómetros de masas se encuentran acoplados con 
sistemas cromatográficos de alta resolución que permiten que los analitos
de una muestra inicialmente muy compleja sean separados e introducidos
gradualmente. Este acoplamiento requiere una interfaz, una 
conexión física y funcional entre el sistema de cromatografía y el espectrómetro,
que consiste generalmente en una columna capilar de caudal controlado.
En ocasiones, como es en el caso de \ac{ESI}, el sistema
de entrada y la fuente de iones forman parte de un único componente.


\item \textbf{Fuente de iones}. Las macromoléculas biológicas, como proteínas y péptidos, no son 
fácilmente volatilizadas.
El desarrollo de las técnicas de ionización suave permitió que
péptidos y proteínas ionizados y relativamente intactos pudieran ser 
introducidos, en fase gaseosa, en un sistema de vacío en los 
espectrómetros de masas para ser analizados. La ionización \ac{ESI} y \mbox{\ac{MALDI}}
son las más comunes en proteómica aunque existen también otros métodos
un poco menos utilizados.

\begin{itemize}

\item \textbf{\ac{MALDI}} (Figura~\ref{fig:maldi_y_esi} a) consiste en embeber la muestra en una matriz líquida, 
que posteriormente se seca,
con alta capacidad de absorber luz UV sobre la que inciden pulsos de luz 
láser UV. Al absorber la energía del láser las moléculas que conforman la
matriz son ionizadas por adición de protones que son luego transferidos
al analito. 

\item En \textbf{\ac{ESI}} (Figura~\ref{fig:maldi_y_esi} b) el analito 
se encuentra en fase líquida en un solvente orgánico volátil como metanol
o acetonitrilo. Esta solución
es conducida a través de un capilar sometido a un campo eléctrico de forma
que las micro-gotas en el ápice del capilar, una vez que la carga supera
un límite, forman un aerosol. Las micro-gotas
del aerosol disminuyen su tamaño por evaporación del solvente, 
reagrupándose en gotas más estables y pequeñas
en un proceso reiterativo, hasta el punto en que las moléculas de analito se repelen con la fuerza
suficiente para superar la tensión superficial y liberarse (explosión de Coulomb)
quedando en suspensión y siendo así introducidos en un sistema vacío hacia el espectrómetro.

%\item El Bombardeo Rápido Atómico, \ac{FAB} consiste en hacer incidir
%un haz de alta energía de átomos de un gas inerte (Argón o Xenón) sobre
%el analito provocando de esa forma su ionización.

%\item En la Desorción por Campo Eléctrico, \ac{FD}
%la muestra se encuentra sometida a un campo eléctrico creado en una 
%superficie, generalmente un filamento de tungsteno, llamado \emph{emisor}.
% Al superar 
%un umbral de diferencia de potencial se produce la desorción e ionización
%del analito.

%\item La Desorción por Plasma, \ac{PD} 
%consiste en hacer uso de un isótopo radiactivo \textsuperscript{252}Cf que
%al sufrir su fisión espontánea produce dos partículas de alta energía
%con trayectorias opuestas, 
%(generalmente \textsuperscript{144}Cs y y \textsuperscript{108}Tc)
%que impactan sobre la muestra provocando su desorción e ionización.


\end{itemize}

Otros tipos de ionización menos empleados en proteómica son los conocidos 
por los acrónimos \ac{FAB}, \ac {FD} y  \ac{PD}.


\figura{Vectorial/maldi_y_esi}{width=.80\textwidth}{fig:maldi_y_esi}%
{Ionización MALDI y ESI}

%\newpage

\item \textbf{Analizador de masas}. El analizador de masas es la parte del instrumento en la que los iones
se separan en base su relación entre la masa y carga (\mz). 
Es el elemento que se usa generalmente para definir el tipo de instrumento.
Existen varios tipos,
y además pueden combinarse en los llamados espectrómetros híbridos. Así, 
un analizador de tipo cuadrupolo puede encontrarse acoplado con un analizador
de tiempo de vuelo o una trampa iónica para formar un \ac{QTOF}
o \ac{QTRAP} respectivamente.
Algunos de los analizadores de masas más empleados en proteómica son los siguientes:


\begin{itemize}

%\item Los \textbf{Analizadores de sector} (magnético o eléctrico)
%aceleran los iones de analito que al atravesar el sector son sometidos
%a un campo con fuerza ortogonal a la trayectoria del ion lo que provoca
%que se desvíen en función de su  relación \mz.

\item \textbf{Analizadores de tipo} \ac{TOF}.
Estos analizadores
usan un campo eléctrico para acelerar los iones de analito. La separación
se produce por la diferencia en el tiempo que éstos invierten en 
recorrer una distancia en el vacío en el interior del analizador, el
llamado \textit{Tiempo de Vuelo}. La aceleración y por tanto
el Tiempo de Vuelo es una función de la relación \mz  de los iones
que impactan en el detector a diferentes tiempos. %Para iones con la misma
%carga, la aceleración depende solo de la masa, los más ligeros 
%llegan al detector antes y los más pesados después.
Los analizadores \ac{TOF} separan todo el paquete de iones ionizados en una
escala dependiente del tiempo y por tanto
se usan generalmente en combinación con ionización \ac{MALDI}, que introduce
iones en el analizador en pulsos de láser en un régimen discontinuo controlado.

\item \textbf{Cuadrupolos}. Los analizadores de tipo cuadrupolo 
(Figura~\ref{fig:Analizadores de masas} a)
reciben su nombre porque constan de cuatro varillas metálicas de sección
hiperbólica en su cara interna enfrentadas
en pares llamados polos con cargas opuestas.
Sobre estos pares, además del potencial eléctrico de corriente continua,
se aplica también una corriente alterna de radiofrecuencia.
Esta conformación permite crear un campo eléctrico oscilante controlado
que desvía selectivamente los iones que pasan a través 
y de esta forma solo los iones en un estrecho margen de valores \mz  podrán llegar a 
impactar en el detector mientras que el resto son desviados y filtrados.
%Una conformación frecuente cosnsite utilizar tres cuadrupolos consecutivos.
%\textit{bla bla etapas de filtrado, mrm, bla bla}
%\textit{bla bla etapas de filtrado, mrm, bla bla}

\item Las \textbf{trampas iónicas} funcionan bajo el mismo principio
físico que los cuadrupolos, pero la conformación en forma de cámara de las
trampas iónicas permite confinar y acumular los iones que luego son 
liberados selectivamente.

\subitem Las trampa iónica \ac{QIT}, descrita por el Nobel Wolfgang Paul en 1960,
(Figura~\ref{fig:Analizadores de masas} c)
consta de  dos electrodos metálicos de sección hiperbólica enfrentados 
y un electrodo toroidal que conforman una cámara donde se acumulan los iones
de analito. En el interior los iones orbitan
en el vacío. El ajuste de la radiofrecuencia permite filtrar selectivamente
los iones, estabilizando aquellos con determinados valores \mz y desestabilizando
el resto, que colisionan con el electrodo y no llegan al detector \citep{Louris1987}.

\figuraEx{Vectorial/Q_QIT_OT}{width=.99\textwidth}{fig:Analizadores de masas}%
{Algunos de los analizadores de masas más comunes son los de tipo
 cuadrupolo (a), Orbitrap (b) y trampa iónica cuadrupolar (c)}{Analizadores de masas}

\subitem Las trampas iónicas \ac{LTQ} o \ac{LIT} consisten
en un sistema de cuadrupolo, que sitúa los iones en un eje radial, y
dos electrodos terminales, uno en cada extremo, que confina los iones longitudinalmente.
Con respecto a las trampas
iónicas tipo QIT, las trampas iónicas \ac{LTQ} tienen una mayor 
capacidad de acumulación de iones y de barrido. Además pueden funcionar
como un cuadrupolo convencional.


\subitem \emph{Orbitrap}
(Figura~\ref{fig:Analizadores de masas} b)
 es un tipo de trampa iónica, relativamente
reciente, desarrollado a finales de los años 90 del s.XX \citep{Makarov2000}.
Consiste en un electrodo en un eje interno rodeado por un electrodo externo
cilíndrico. Los iones son introducidos tangencialmente desde la fuente 
de ionización y, al ajustar la diferencia de potencial, son atrapados en
órbitas elípticas longitudinales, en las que la atracción hacia el eje interno 
es compensada por la fuerza centrífuga. La relación \mz se determina a partir 
de la frecuencia angular de la oscilación de los iones en torno al 
electrodo longitudinal interno.


\subitem Los analizadores de tipo 
\ac{FTICR} se basan en confinar los iones en una celda ICR
donde un campo magnético homogéneo somete los iones a seguir una trayectoria %de forma que son sometidos a seguir una trayectoria
circular %. La Fuerza de Lorentz obliga a que un ion con un vector de velocidad
%ortogonal al campo magnético experimente una fuerza ortogonal al plano 
%definido por la velocidad y el campo magnético. Esto provoca que las 
%las partículas describan movimientos circulares 
con una frecuencia de rotación
característica de cada relación \mz y del valor del campo. Al aplicar
un campo eléctrico de igual frecuencia a la frecuencia de rotación, la 
partícula es excitada para seguir una trayectoria más larga aumentando
el radio de giro %. En la celda ICR, el conjunto de iones es excitado 
%durante unos milisegundos de forma que los iones adquieren diferentes
%órbitas de movimiento ciclotrónico que alcanzan las placas de detección.
provocando que los iones alcancen las placas de detección.
La señal formada por la mezcla de las frecuencias de todos los iones
es entonces deconvolucionada mediante la transfomada de Fourier que
 permite la detección simultánea de todas las frecuencias.


\end{itemize}




\item \textbf{Detector}
El detector es elemento final de un espectrómetro de masas. Registra la
corriente producida por el haz de iones que incide sobre él convirtiéndola
en una señal eléctrica medible. Los detectores más utilizados en 
espectrometría de masas son los \emph{multiplicadores de electrones}.
Este tipo de detector utiliza la energía cinética de los iones que inciden sobre una 
placa sobre la que se provoca una segunda descarga de electrones que inciden en otra placa
y así sucesivamente de forma que se produce una reacción en cadena para conseguir la amplificación de la señal. 
%En principio, pueden utilizarse tantas placas como se quiera, aunque 
%generalmente se utilizan entre 10 y 16. Por medio de este detector, se 
%consiguen amplificaciones dela corriente iónica con factores de 
%multiplicación de 10\textsuperscript{6} o mayores

\end{enumerate}



La \textit{sensibilidad}, \textit{resolución}, \textit{precisión} y 
\textit{exactitud} son parámetros importantes en espectrometría de masas 
ya que determinan notablemente la cantidad y calidad de información
del espectro generado, lo que a su vez, es esencial para identificar
el péptido que origina el espectro. 

La \textit{sensibilidad} de un espectrómetro de masas es la 
capacidad para detectar masas muy pequeñas. Puede llegar a ser de hasta
unas pocas partes por millón (ppm) en el caso de instrumentos de alta
precisión como el \ac{LTQ}-Orbitrap, pero requiere un ajuste óptimo de múltiples
parámetros como la calibración del instrumento o la temperatura entre
otros.


La \textit{resolución} es la capacidad para discernir señales que realmente 
corresponden a diferentes iones dentro de una ventana o margen de valores \mz .
Esto es esencial para evitar la co-fragmentación, es decir, obtener 
fragmentos de iones precursores diferentes con valores \mz similares, o cuando
se requiere conocer la distribución isotópica de un ion.
La resolución, R,  se define como la diferencia entre las masas de dos picos
adyacentes que están resueltos

\begin{equation}
\label{eq:resolucion}
R = \frac{M}{\Delta{M}}
\end{equation}
donde M es el valor entero más próximo de masa del primer pico y $\Delta${M}
es el incremento de \mz a una determinada altura del pico. Frecuentemente
se usa un 50\% de altura del pico, en ese caso el parámetro es el denominado \ac{FWHM}.
%La resolución es un parámetro específico de cada analizador de masas. Otros
%parámetros, relacionados aunque no específicos del instrumento son la exactitud
%y la precisión.

La \textit{exactitud} de la medida de la masa molecular 
es la diferencia entre el valor \mz obtenido para un ion y su valor real.
Se expresa generalmente en partes por millón (ppm) y representa el error 
del valor \mz obtenido con respecto al valor verdadero.

La \textit{precisión} es una medida de la dispersión de una serie de 
mediciones obtenidas para un analito determinado (en condiciones
experimentales equiparables) con respecto a un valor
promedio de referencia. El parámetro que se emplea generalmente como medida
de precisión es la desviación estándar {\large$\sigma$}, equivalente a la raíz
cuadrada de la varianza.


%---------------------------------------------------------------------
%---------------------------------------------------------------------


\subsection{Espectrometría de masas en tándem. MS/MS}
%\addcontentsline{toc}{subsection}{Espectrometría de masas en Tandem. MS/MS}


Los péptidos, separados en el espectrómetro de masas en base a su 
relación \mz , generan señales cuyas intensidades son registradas en el 
detector e interpretadas como un espectro. 
El objetivo básico en proteómica consiste en la elección del mejor
péptido de una lista de posibles candidatos que ha generado el espectro,
y por extensión la inferencia de la proteína originaria.
Tras la adquisición de los espectros, el análisis informático
consiste, en esencia, en estimar el grado de similitud entre %los valores \mz empíricos 
%obtenidos en el espectro y los valores \mz calculados que teóricamente
%se producen a partir de una digestión predicha computacionalmente de las
el espectro empírico obtenido y espectros teóricos derivados de 
secuencias en una base de datos de referencia.

En ocasiones, cuando la proteína original se encuentra relativamente
aislada, el espectro que generan los péptidos que se detectan en el 
instrumento es suficientemente informativo y específico de la proteína original y 
ésta puede ser identificada. Este es el principio de la técnica conocida
como huella de masas peptídicas, descrita en la sección \ref{cap1:subsec:PMF}.
Sin embargo, esta técnica requiere que la proteína se encuentre aislada
y el rendimiento que ofrece es, por tanto, limitado. 

\figuraEx{Vectorial/tandem_ms}{width=.99\textwidth}{fig:tandem_ms}%
{En la espectrometría de masas en tándem se seleccionan péptidos precursores,
 generalmente los de mayor intensidad en el espectro MS\textsuperscript{1}, para %
ser fragmentados y generar el espectro MS/MS o MS\textsuperscript{2}}%
{Espectrometría de masas en tándem. MS/MS}

En la espectrometría de masas \ac{MSMS} o MS\textsuperscript{2},
 los péptidos, una vez
ionizados y en el interior del analizador, son sometidos a una 
fragmentación adicional. (Figura~\ref{fig:tandem_ms}).
%\begin{itemize}
%\item En la \emph{Disociación Inducida por Colisión}, CID
%\end{itemize}
Los péptidos se fragmentan, generando iones más pequeños
lo que hace que el patrón de fragmentación sea más específico de la 
secuencia original.
Esto aumenta el poder de resolución del análisis, ya que permite 
distinguir péptidos que, intactos, tienen masas muy similares,
pero cuyos patrones de fragmentación MS/MS son diferentes.
Esto posibilita, además, partir de muestras con mezclas de proteínas 
más complejas incrementando así el rendimiento del experimento.

El proceso que conduce a la adquisición de espectros conlleva varias etapas.
En primer lugar el instrumento escanea todos los péptidos ionizados
introducidos en el espectrómetro y registra los llamados espectros 
MS\textsuperscript{1}, valores \mz y sus correspondientes intensidades
para cada ion.
A continuación, en función de la intensidad registrada en 
MS\textsuperscript{1}, se seleccionan y aislan algunos de estos iones, \emph{precursores},
 para ser fragmentados en péptidos más 
pequeños, \emph{fragmentos}, en el interior del analizador.
El espectro MS\textsuperscript{2} adquirido o espectro de fragmentación,
registra los valores \mz e intensidades de los fragmentos de cada
uno de los péptidos precursores aislados y fragmentados. 
El patrón de fragmentación codificado en los espectros MS\textsuperscript{2}
contiene la información necesaria para deducir la secuencia aminoacídica
del péptido que lo origina.

En algunos análisis puede ser necesario realizar fragmentaciones adicionales
que permitan un poder de resolución mayor aún. Estos análisis
se conocen como MS\textsuperscript{n}, donde \emph{n} es el número de 
fragmentaciones y etapas de análisis de masas consiguientes.

A este método de adquisición de espectros de fragmentación, en el que
los péptidos precursores son seleccionados para ser fragmentados en base 
las intensidades en el espectro MS\textsuperscript{1} se le denomina también mediante
el acrónimo \ac{DDA}
%En la fragmentación, la estructura del esqueleto peptídico se rompe en
%los enlaces peptídicos, el punto de menor energía de la estructura

Los fragmentos originados a partir del péptido, según la nomenclatura
de Roepstorff \citep{Roepstorff1984}, se clasifican, en función del punto 
donde se produce la ruptura, en las denominadas
series \emph{x}, \emph{y} y \emph{z} si la carga del ion permanece en el
extremo carboxilo-terminal y las series \emph{a}, \emph{b} y \emph{c} si la 
carga permanece en el extremo amino-terminal. Además se añade un sub-índice
que indica el número de residuos en el fragmento (Figura~\ref{fig:peptide_fragmentation}).
Generalmente, los iones más abundantes e informativos son los \emph{b-} e \emph{y-},
 generados por la fragmentación en el enlace peptídico entre aminoácidos, 
el punto de menor energía de la estructura.
En analizadores tipo cuadrupolo o \ac{QTOF} predominan los iones \emph{y-},
mientras que en las trampas iónicas se generan igualmente \emph{b-} e \emph{y-}
\citep{Steen2004}.


\figura{Vectorial/roepstorff_nomenclature}{width=.70\textwidth}{fig:peptide_fragmentation}%
{Nomenclatura de Roepstorff para los fragmentos en MS/MS} 


%Doubly charged tryptic peptides mainly yield singly charged y- and b-ions.
%In addition, a-ions (loss of a C=O group or a mass difference of 27.9949 Da 
%relative to the b-ion) can occur, but this is normally only observed for 
%the b2-ion, which gives rise to the characteristic a2/b2-fragment ion 
%pair in the lower mass range72 (see figure, part b). Apart from the ion 
%types shown, 'satellite' fragment ions due to the further loss of NH3 or
%H2O can be produced. These ions are designated, for example, am - NH3 or
%y (n-m) - H2O. Fragmentation both amino-terminal to and carboxy-terminal 
%of the same amino acid produces immonium ions, which are diagnostic of 
%modified amino acids such as phosphotyrosine and/or hydroxyproline73.


\subsubsection*{Técnicas de fragmentación}

La fragmentación \ac{CID} 
es uno de los métodos de fragmentación más frecuentemente utilizados en
espectrometría de masas para proteómica.
Consiste en hacer colisionar a las moléculas de analito con átomos o moléculas
de gases nobles, químicamente inertes. Argón o Xenón 
son generalmente usados en triples cuadrupolos y Helio en las 
trampas iónicas \citep{Burlingame1996}.
La colisión provoca que parte de la energía cinética del ion sea transformada
en energía vibracional lo que provoca la ruptura del esqueleto peptídico.
La fragmentación tipo CID genera una elevada proporción de iones de las 
series \emph{b-} e \emph{y-}.

%%Sin embargo, existen también otros tipos de fragmentación. 
%%Atencion, con el siguiente parrafito resumo ETD, ECD y HCD :

Otros tipos de fragmentación son \ac{ETD} \citep{Syka2004} en la que los iones de analito
con carga positiva interaccionan con aniones que les transfieren un 
electrón produciendo una fragmentación con presencia de iones \emph{c-} y \emph{z-};
la disociación \ac{ECD} \citep{Zubarev1998},
consistente la interacción del analito con electrones suministrados 
directamente; y, por último, la disociación \ac{HCD}
usada en analizadores tipo Orbitrap \citep{Olsen2007}, y que al igual que 
CID genera iones \emph{b-} e \emph{y-}, si bien, debido a la mayor energía de
activación, los iones \emph{b-} sufren fragmentaciones adicionales generando
iones \emph{a-} y otras especies de menor tamaño.

%En la Disociación por Transferencia de Electrones, \ac{ETD}, \citep{Syka2004}, los iones de analito
%con carga positiva interaccionan con aniones que les transfieren un 
%electrón produciendo una fragmentación con presencia de iones \emph{c-} y \emph{z-}.
%Esta técnica funciona bien para iones de analito con carga \emph{z > 2}
%y para péptidos largos e incluso para proteínas enteras. Además produce
%una fragmentación en la que las cadenas laterales y \ac{PTM} quedan intactas.
%Estas cualidades hacen ETD interesante para proteómica \emph{top-down},
%que intenta identificar proteínas intactas, y también
%para experimentos orientados a la deteccion de péptidos con \ac{PTM}.


%En la Disociación por Captura de Electrones, \ac{ECD} \citep{Zubarev1998},
%como en \ac{ETD}, la fragmentación se produce por la interacción del analito
%con electrones que, en este caso, son suministrados por introducción directa.
% \ac{ECD} se usa generalmente en espectrómetros
%tipo \ac{FTICR} y en trampas iónicas y genera abundantes fragmentos de series
%\emph{c-}, \emph{z-} y, aunque en menor medida, también de la serie \emph{b-}.
%Al igual que ECD, es particularmente efectivo para el estudio de péptidos
%con \ac{PTM}

%Otro tipo de fragmentación es la Disociación por Colisión de Alta Energía, \ac{HCD}
%usado en analizadores tipo Orbitrap \citep{Olsen2007}. Al igual que \ac{CID}
%genera iones \emph{b-} e \emph{y-}, si bien, debido a la mayor energía de
%activación, los iones \emph{b-} sufren fragmentaciones adicionales generando
%iones \emph{a-} y otras especies de menor tamaño. Este tipo de espectros
%de fragmentación son más informativos, pero a cambio, requieren analizadores de alta
%precisión.


%-------------------------------------------------------------------
%-------------------------------------------------------------------


%\phantomsection
\section{Digestión de proteínas en péptidos}
%\addcontentsline{toc}{section}{Digestión de proteínas en péptidos}
%\label{cap1:sec:Digestión de proteínas en péptidos}

Tras la obtención de una muestra de proteínas, ya sea una mezcla compleja
o una proteína más o menos aislada y purificada, el primer
paso en un experimento de proteómica consiste en someter a las proteínas
a la acción de una enzima proteolítica
que corta en puntos específicos de la secuencia y que las digiere en 
un conjunto de péptidos. 
Sin embargo, sabiendo que ciertos espectrómetros de masas tienen la capacidad de medir
masas de proteínas intactas, podemos preguntarnos:
 
\emph{¿por qué hacer una digestión que aumenta el grado de 
complejidad de la muestra y que supone el problema añadido de la inferencia
de la proteína originaria a partir de sus péptidos constituyentes?}
%% VER ABC's and XYZ's of peptide sequencing de Mann M
o dicho de otra manera 
%% Why are peptides, and not proteins, sequenced?
\emph{¿es necesario el paso intermedio de digestión en 
péptidos para luego inferir las proteínas originales?}

La respuesta a estas preguntas, revisada en \citep{Steen2004}, tiene que ver, sobre todo, con limitaciones
técnicas. El principal motivo es que la sensibilidad de los espectrómetros
es menor para proteínas intactas que para péptidos.
Pero además, las proteínas intactas pueden ser difíciles de manipular,
algunas, como las proteínas de membrana son insolubles en condiciones en
que otras sí lo son. Muchos detergentes comúnmente usados interfieren en
MS ya que son fácilmente ionizables y se encuentran en gran cantidad en 
proporción a las proteínas \citep{Hatt1997}.
%La cantidad de 
%posibles formas en que una proteína es procesada, incluyendo \ac{PTM} 
%en sus péptidos, y variaciones conformacionales entre
%otras, hace que la combinación de isoformas posibles y sus masas sean 
%imposibles de discernir por MS. Por otra parte, para identificar a la
%proteína originaria se requiere información de la secuencia y para esto
%los espectrómetros son mas eficientes si se analizan secuencias de un 
%tamaño limitado en número de aminoácidos.

%~ A pesar de estas limitaciones los espectrómetros sí permiten inferir, 
%~ al menos parcialmente,
%~ secuencias a partir de proteínas intactas y con ello identificarlas.
%~ Este es el objetivo de la llamada proteómica \textit{top-down} (de 
%~ arriba a abajo)
%~ 
%~ Sin embargo la proteómica \textit{bottom-up} (\textit{de abajo a arriba}),
%~ en la que se infiere la presencia de proteínas a partir de sus péptidos,
%~ es la técnica más extendida.

La digestión consiste en la rotura de proteínas en 
péptidos por acción de una enzima proteolítica. Tradicionalmente se ha utilizado
para esto \emph{tripsina}, que rompe la secuencia aminoacídica a continuación, 
en el lado carboxilo-, de
 Arginina (R) o Lisina (K) a menos que exista una Prolina (P) adyacente.
Los péptidos generados por acción de la tripsina, llamados péptidos
\emph{trípticos}, tienen un tamaño adecuado, dada la frecuencia media de R y K, 
para el análisis por espectrometría de masas lo que explica la popularidad 
de esta proteasa.

También es posible la utilización de otras proteasas siempre que se 
conozca su patrón de corte. Es de hecho una aproximación inevitable
para aquellos casos en que la tripsina no sea útil, por ejemplo, debido a
una baja frecuencia de R y K que no generen péptidos del tamaño adecuado.



%-------------------------------------------------------------------
%-------------------------------------------------------------------


%\phantomsection
\section{Proteómica en gel}
%\addcontentsline{toc}{section}{Proteómica en gel}
%\label{cap1:sec:Proteómica en gel}

La separación de proteínas por electroforesis \ac{PAGE}
es una técnica, o serie de técnicas con variantes, que consiste en separar
proteínas presentes en una muestra inicial en base a propiedades
fisico-químicas diferenciadoras como su carga, tamaño y/o su punto isoeléctrico.
En función del número de estas propiedades que se aprovechan para separar,
 en mayor o menor grado, las proteínas de una muestra
se distinguen básicamente dos tipos de \ac{PAGE}:

En la electroforesis \ac{1DPAGE},
las proteínas se separan en función de su peso molecular, las más pequeñas
avanzan más en el gel. 
En la electroforesis  \ac{2DPAGE},
\citep{Klose1975,OFarrell1975}, las proteínas se separan en una primera dimensión (sobre una tira con un
gradiente de pH inmovilizado) en función de su punto isoeléctrico para
posteriormente, aplicar la segunda dimensión, equivalente a 1DPAGE.


%~ \begin{itemize}
  %~ \item Electroforesis en Gel de PoliAcrilamida Monodimiensional, \ac{1DPAGE}. 
  %~ En este tipo de geles las 
  %~ proteínas se separan en función de su peso molecular. La electroforesis
  %~ hace que las proteínas mas pequeñas, de menor peso molecular, se desplacen
  %~ mas lejos en el gel, sometido a una diferencia de potencial.
  %~ \item Electroforesis en Gel de PoliAcrilamida Bidimiensional, \ac{2DPAGE}.
   %~ En este caso, las proteínas 
  %~ se separan en una primera dimensión en función de su punto isoeléctrico.
  %~ Las proteínas se desplazan sobre una tira con un gradiente de pH hasta
  %~ situarse en un punto donde su carga neta se equilibra con la de su 
  %~ entorno. A continuación la tira se coloca en la cabecera de un gel y se
  %~ aplica la segunda dimensión, de modo que se las proteínas se someten a
  %~ una separación adicional, en este caso por peso molecular, al igual que en un gel 1D.
%~ \end{itemize}

Otra clasificación posible de las técnicas PAGE puede establecerse en
función de si se usan condiciones desnaturalizantes o no. 
Entre las técnicas que usan geles desnaturalizantes probablemente la más
empleada sea la electroforesis \ac{SDSPAGE}.
Y entre las que usan condiciones nativas o no desnaturalizantes, la llamada Blue Native, 
empleada para estudiar proteínas agrupadas en complejos.

%\begin{itemize}
%  \item Geles desnaturalizantes.
%   Electroforesis en Gel de PoliAcrilamida con DodecilSulfato Sódico, \ac{SDSPAGE}
%  \item Condiciones nativas o no desnaturalizantes
%  Blue Native
%\end{itemize}

La proteómica en gel ha sido (y continúa siendo) una técnica muy empleada 
en laboratorios de todo el mundo. Tiene algunas limitaciones, como 
el hecho de que proteínas de bajo peso molecular o muy hidrofóbicas 
no son fácilmente observables \citep{Gygi2000}, 
o una limitación en el número de proteínas identificables a partir de un gel
que dificilmente puede superar el millar \citep{Klose1995}.

Sin embargo, este tipo de estudios sigue 
teniendo un nicho en la proteómica actual \citep{Rogowska-Wrzesinska2013}.
Una ventaja notable es que permite la visualización, identificación y cuantificación 
de proteínas intactas. La particular capacidad de la proteómica en gel para
separar proteínas con pequeños cambios en sus puntos isoeléctricos, \emph{pI},
permite discernir entre isoformas de proteínas, o versiones de la misma 
proteína con \ac{PTM}, lo es difícil de 
conseguir con otro tipo de aproximaciones.


%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\subsection{Huella de masas peptídicas}
\label{cap1:subsec:PMF}

%\addcontentsline{toc}{subsection}{Huella Peptídica}
%The anchor of a bookmark and its parent's must not be the same. Added a new anchor

La huella de masas peptídicas de una proteína se refiere al hecho de que el 
patrón de fragmentación de una proteína en los péptidos que la constituyen
utilizando una enzima proteolítica determinada, es muy específico de la
proteína originaria (siempre y cuando se conozca el patrón de corte de la 
enzima, como es el caso de la tripsina)
de forma que el espectro que generan puede ser utilizado para identificarla. 
Sin embargo, a pesar de esta especificidad, la enorme variedad de
proteínas implica una mayor aún variedad de posibles péptidos generados a partir de 
ellas que pueden tener masas muy similares. Por ese motivo,
para obtener una huella peptídica se requiere que la proteína se encuentre previamente aislada, 
 generalmente a partir de una \textit{mancha} o \textit{spot} proteico de \ac{2DPAGE}

La técnica de la huella peptídica, \ac{PMF}, desarrollada a principios
de los años 90 por varios grupos independientemente \citep{Pappin1993,Henzel1993,Mann1993a}
se lleva a cabo generalmente por 
espectrometría de masas MALDI-TOF(TOF). Esto significa que, una vez obtenidos los
péptidos correspondientes a la proteína del \textit{spot}, éstos se sitúan
en una matriz \ac{MALDI}, donde son ionizados e introducidos en un analizador
\ac{TOF}.
Una vez obtenido el espectro patrón de masas peptídicas, el proceso 
de análisis consiguiente es similar al que se hace en la
proteómica \textit{shotgun}. Como se describe en las
secciones siguientes, la identificación
del péptido responsable del espectro se realiza utilizando un motor de búsqueda, 
que compara los valores de \mz del espectro 
obtenidos empíricamente con los valores de \mz calculados a partir
de las secuencias de péptidos trípticos teóricos.



%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Proteómica \textit{shotgun}}
%\addcontentsline{toc}{section}{Proteómica de alto rendimiento \textit{shotgun}}
\label{cap1:sec:Proteómica shotgun}

La proteómica \textit{shotgun} (el término inglés se encuentra muy establecido)
es la técnica de elección para la mayoría
de estudios proteómicos enfocados a obtener un alto rendimiento.
El nombre \textit{shotgun} proviene 
de una analogía con las técnicas clásicas de secuenciación genómica donde 
el ADN es fragmentado en puntos no focalizados, indiscriminadamente,
en secuencias más pequeñas que posteriormente son 
ensambladas. En la proteómica \textit{shotgun} las proteínas son 
fragmentadas en péptidos a partir de los cuales se infiere finalmente 
la proteína original. Implica varios pasos descritos en las siguientes 
secciones.

\figuraEx{Vectorial/overview_of_shotgun_proteomics}{width=.99\textwidth}{fig:overview_of_shotgun_proteomics}%
{Etapas en un experimento de proteómica \textit{shotgun}. En primer lugar
la muestra de proteínas es digerida en péptidos. A continuación éstos
son separados mediante algún tipo cromatografía, frecuentemente HPLC.
A medida que eluyen, los péptidos
separados, son introducidos en el espectrómetro de masas que genera
un espectro de fragmentación MS/MS. Por último el motor de búsqueda
compara los espectros empíricos con espectros teóricos asignando una puntuación.}{Etapas en un experimento de proteómica \textit{shotgun}}


%-------------------------------------------------------------------
%-------------------------------------------------------------------


%\phantomsection
\subsection{Separación de péptidos y proteínas sin gel}
%\addcontentsline{toc}{subsection}{Separación multidimensional de péptidos}

A diferencia de la técnica de la Huella Peptídica donde cada proteína se encuentra
relativamente aislada, en la proteómica de alto rendimiento o
\mbox{\textit{shotgun}}, puesto que el objetivo es identificar el máximo número de 
proteínas en un solo experimento, se parte de una muestra
más compleja. Esto es importante porque, 
sabiendo que a partir de cada proteína se generan múltiples
péptidos (trípticos), el grado de complejidad de la muestra aumenta
 enormemente tras la digestión.
Por este motivo, para evitar que la mezcla de péptidos sea demasiado 
compleja para la resolución en el análisis MS,
previamente a la introducción de los péptidos en el espectrómetro, se 
realiza una cromatografía que permite separar los péptidos para que 
sean ionizados y lleguen al analizador de masas gradualmente.

Opcionalmente esta separación puede comenzar a nivel de proteína por
electroforesis en un gel \ac{1DPAGE}, o incluso a un nivel estructural 
superior, por ejemplo, por fraccionamientos sub-celulares correspondientes a distintos 
orgánulos.

\medskip
\subsubsection*{Cromatografía Líquida de Alto Rendimiento. HPLC}


Pero el fraccionamiento más importante se hace a nivel de péptido, tras 
la digestión de las proteínas, 
por \ac{HPLC}.
El funcionamiento básico general en HPLC consiste en hacer pasar la muestra
a través de una fase estacionaria en el interior de una columna mediante 
el bombeo a alta presión de una fase móvil. De esta forma los componentes 
de la muestra se retrasan diferencialmente en función de sus interacciones 
químicas con la fase estacionaria a medida que atraviesan la columna. 
La fase móvil suele ser una combinación, en proporciones variables,
de un componente acuoso al que se añade un ácido (trifluoroacético o fórmico) 
y un solvente orgánico (comúnmente acetonitrilo o metanol).
Esta proporción en la composición de la fase móvil puede ser constante 
(cromatografía isocrática) o variable, en gradiente de elución. 
En un gradiente típico, al aumentar la proporción del solvente orgánico, 
los analitos de la muestra irán progresivamente teniendo mayor afinidad 
por la fase móvil y se separan de la fase estacionaria. El \textit{Tiempo
de Retención} o \textit{Tiempo de Elución} es el tiempo que necesita un
analito para atravesar la columna. Siempre que las condiciones cromatográficas
permanezcan invariables el tiempo de retención de un analito es una
característica identificativa.

 %Además frecuentemente son combinables
%y pueden emplearse secuencialmente. Algunos de los tipos de LC más utilizados
%se describen a continuación.

%\begin{itemize}
%  \item Cromatografía líquida en fase reversa (RP-LC)
El tipo más común de cromatografía usada en experimentos de proteómica
es la que se conoce como \ac{RPHPLC}.
En ella los analitos de la muestra se separan en base a su carácter
hidrofóbico. 
La fase estacionaria, apolar, está compuesta por unas micro-esferas de 
sílice cubiertas de cadenas alquilo con 18 átomos de C (C18).
Un gradiente en que el solvente orgánico aumente gradualmente y en
proporción inversa al componente acuoso, provoca que los analitos
más polares eluyan primero integrados en la fracción acuosa cuando 
hay una mayor proporción de ésta, mientras que los más 
hidrofóbicos son retenidos durante más tiempo.
%  \item Cromatografía de intercambio catiónico
Además, la cromatografía, usando una terminología similar a la usada para la separación
de proteínas en gel, también puede ser multi-dimensional.
La tecnología denominada \ac{MudPIT}
\citep{Wolters2001} integra una primera dimensión de separación usando 
una columna \ac{SCX} y una segunda dimensión consistente 
en una cromatografía en fase reversa.
%\end{itemize}

%\bigskip{}

A continuación, una vez producida la separación cromatográfica, los
péptidos son ionizados e introducidos en el espectrómetro de masas.
En ocasiones, como el caso de la ionización ESI, el sistema de entrada
y la fuente de iones forman parte de un único componente que se encuentra 
acoplado (\textit{on-line}) al espectrómetro de masas.

Tras la adquisición experimental de los espectros, el paso
siguiente en un experimento de proteómica \textit{shotgun} implica el
análisis computacional de esos espectros cuyo objetivo final es la 
obtención de una lista de proteínas que presumiblemente se encuentran en 
la muestra. Este análisis computacional, a su vez, consta de varios procesos 
secuenciales, principalmente la 
\hyperref[cap1:sec:Asignación péptido-espectro]{asignación de secuencias peptídicas a cada espectro}
(sección \ref{cap1:sec:Asignación péptido-espectro}),
\hyperref[cap1:sec:Inferencia de proteínas a partir de péptidos]
{la inferencia de las proteínas a partir de esos péptidos}
(sección \ref{cap1:sec:Inferencia de proteínas a partir de péptidos})
y una \hyperref[cap1:sec:Evaluación estadística de los resultados]
{evaluación estadística que aporta medidas de fiablidad a la identificación}
(sección \ref{cap1:sec:Evaluación estadística de los resultados}).


%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Asignación péptido-espectro}
%NOTA: esto no es una subseccion de Proteómica a gran escala porque puede ser igual para proteomica en gel, ya tal
\label{cap1:sec:Asignación péptido-espectro}
%\addcontentsline{toc}{section}{Asignación Péptido-Espectro}


En un experimento típico de proteómica \textit{shotgun} pueden 
generarse miles de espectros por hora. La interpretación manual, por lo
tanto no es una opción práctica. Diversas aproximaciones computacionales
y herramientas de \textit{software} se han desarrollado para facilitar 
esta tarea de asignación de secuencias peptídicas a los espectros MS/MS. 
A cada una de estas parejas péptido-espectro 
se les denomina generalmente \ac{PSM}.

Las estrategias utilizadas para la obtención de una lista de \ac{PSM} básicamente pueden
 clasificarse en tres tipos. La más extendida es la 
\hyperref[cap1:subsec:búsqueda secuencia]{búsqueda utilizando bases de datos de secuencias},
consistente en establecer una correlación entre
el espectro MS/MS obtenido empíricamente y espectros teóricos predichos 
a partir de secuencias. 
Otra estrategia, usada en casos en que el genoma del 
organismo objeto de estudio no está (o sólo parcialmente) secuenciado, es 
\hyperref[cap1:subsec:otras estrategias de asignación péptido-espectro]{la secuenciación 
\textit{de novo}} en la que la secuencia se infiere directamente del espectro
sin ayuda de una base de datos de referencia.
El tercer tipo de aproximación, la 
\hyperref[cap1:subsec:otras estrategias de asignación péptido-espectro]
{búsqueda basada en bibliotecas de 
espectros}, requiere una recopilación, lo más extensa posible, de
espectros MS/MS adquiridos previamente y ya asignados a péptidos,
que son comparados directamente con los espectros empíricos adquiridos.



%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\subsection{Búsqueda en bases de datos de secuencias}
\label{cap1:subsec:búsqueda secuencia}
%\addcontentsline{toc}{subsection}{Búsqueda en bases de datos de secuencias}

La búsqueda utilizando bases de datos de secuencias es el principal y más
 extendido método
de asignación de una secuencia peptídica a un espectro MS/MS 
(figura~\ref{fig:spectrum_interpretation_2}).
Existen una gran variedad de herramientas computacionales llamadas 
motores de búsqueda diseñadas para realizar
esta tarea. 


\figuraEx{Vectorial/spectrum_interpret_from_man_to_auto_2}{width=.70\textwidth}{fig:spectrum_interpretation_2}%
{Interpretación automática de espectros MS/MS. Gracias a la información
disponible sobre la presencia de los diferentes tipos de iones
se puede elaborar una lista de péptidos candidatos que han generado
el espectro empírico y para cada uno de ellos comparar y evaluar su similitud.}
{Interpretación automática de espectros MS/MS}


Los 
\hyperref[cap1:subsubsec:motores de búsqueda]{motores de búsqueda}
 son un tipo de programas informáticos a los que
se les suministra como entrada datos correspondientes a una lista de 
espectros MS/MS empíricos y una serie de
parámetros que tener en cuenta para restringir la búsqueda. 
El programa compara estos espectros reales registrados con espectros
teóricos que es posible obtener gracias a diversas fuentes de información 
disponible como el patrón de corte de la enzima proteolítica utilizada,
los valores \mz de los fragmentos que se producirían a partir de los péptidos,
la frecuencia estimada de cada tipo de fragmento y las secuencias de las
proteínas en una base de datos de referencia.
En el proceso, el espacio de búsqueda se acota mediante la selección
de una lista de péptidos posibles, 
(candidatos que cumplen unos criterios determinados), que posiblemente han generado el 
espectro MS/MS y a continuación se ordenan utilizando una puntuación 
función del grado de similitud entre el espectro empírico y el teórico.

%SEQUEST (ref) y Mascot (ref) son algunos de los primeros motores de búsqueda, muy
%populares, pero existe una gran variedad de este tipo de software, 
%disponible tanto en aplicaciones libres como comerciales.


%\textit{TABLA LISTA MOTORES DE BÚSQUEDA}.


%-------------------------------------------------------------------
%-------------------------------------------------------------------

\subsubsection*{Elaboración de una lista de péptidos candidatos}

Para reducir el espacio de búsqueda entre todos los posibles péptidos
candidatos que explican el espectro MS/MS y así reducir el coste 
computacional, el motor de búsqueda requiere, como estrategia heurística,
una serie de parámetros proporcionados por el usuario. Éstos, básicamente, reflejan
conocimiento previo sobre el experimento y pueden ser entendidos como
información auxiliar para facilitar la distinción entre identificaciones
auténticas o reales e identificaciones falsas.
Los más importantes de estos parámetros son la enzima utilizada y el rango
de masas en el que debe encontrarse el ion precursor.

\begin{itemize}

\item{
La selección de la enzima proteolítica utilizada
limita la digestión predicha computacionalmente a aquellos péptidos que cumplan
el patrón de corte conocido, filtrando el resto de posibles péptidos. 
Con esto se reduce enormemente el número de comparaciones que el motor
de búsqueda debe realizar y, por tanto, el tiempo empleado para ello. Sin
embargo, al restringir el tipo de enzima, se imposibilita la identificación
de péptidos con rupturas inespecíficas (por ejemplo el procesamiento post-
traduccional que provoca la liberación del péptido señal o por 
proteasas contaminantes presentes en la muestra)
}

\item{
El establecimiento de un rango o ventana
de tolerancia de masas, tanto a nivel de péptido precursor como a nivel
de fragmentos, permite excluir aquellos péptidos y fragmentos que se encuentren
fuera de dicho rango. Sólo los espectros teóricos de aquellos péptidos que 
cumplen este requisito son comparados con el espectro empírico y  puntuados en base a su similitud.
La elección de esta tolerancia depende del tipo de espectrómetro utilizado, 
así, para equipos de alta resolución tipo Orbitrap o FTICR se puede ajustar
a valores inferiores a 1 Da.
}

\end{itemize}

%~ \medskip

Otros parámetros que se proporcionan al \textit{software} y que afectan 
notablemente a la creación de la lista de candidatos y por tanto también
al coste computacional son, la selección de masa mono-isotópica o masa
promedio (es decir, considerar que todos los átomos de C se encuentran en 
su forma \textsuperscript{12}C o bien que exista una proporción variable de
isótopos \textsuperscript{13}C); el número de puntos de corte no efectuados
permitidos dentro de la secuencia del precursor;  la existencia de 
modificaciones post-traduccionales y otras modificaciones permitidas 
(variables o fijas) que ocurren en el proceso experimental; 
y la selección del tipo de iones fragmento a buscar.

%~ \item {
%~ Masa mono-isotópica o Masa promedio.
%~ A partir de un espectro MS se obtiene el valor \mz y con ello
%~ la masa del péptido. 
%~ Este valor de masa del péptido puede aproximarse más a la masa mono-isotópica,
%~ aquella en la que se considera que todos los átomos de C se encuentran 
%~ en su forma \textsuperscript{12}C
%~ o bien, puede considerarse que existe una proporción variable de isótopos 
%~ \textsuperscript{13}C, y calcularse una masa promedio. Generalmente
%~ para espectros de alta resolución la masa del péptido calculada suele
%~ acercarse más al valor mono-isotópico, mientras que para instrumentos 
%~ de baja resolución suele elegirse el valor de masa promedio.
%~ }

%~ \item {
%~ El número de puntos de corte no efectuado permitidos dentro de la 
%~ secuencia del precursor. La eficiencia de las enzimas proteolíticas 
%~ no es del 100\%, por tanto, este parámetro hace que el motor de búsqueda
%~ tenga también en cuenta péptidos con K y/o R en su secuencia (en el caso
%~ de una digestión con tripsina)
%~ }

%~ \item{
%~ Modificaciones post-traduccionales y otras modificaciones permitidas 
%~ que ocurren en el proceso experimental.
%~ Algunas modificaciones ocurren como consecuencia de la manipulación 
%~ experimental, como la carbamidometilación en las cisteínas (C), un 
%~ artefacto que se produce (por reducción y alquilación por acción de 
%~ Iodoacetamida) en todas las C para evitar la formación de puentes di-sulfuro. 
%~ Otro tipo de modificaciones son las \ac{PTM} que ocurren
%~ en la célula naturalmente y que suponen transformaciones estructurales y/o funcionales
%~ en las proteínas, como las fosforilaciones que implican un desplazamiento 
%~ en masa promedio de 79.979 Da sobre residuos de serina (S), treonina (T) o tirosina(Y);
%~ o las glicosilaciones que implican la adición de oligosacáridos sobre grupos
%~ amino de asparagina (N) o glutamina (Q) (N-glicosilación); o hidroxilo (O-glicosilación) 
%~ en serinas (S) o treoninas (T)
%~ Además puede considerarse que las modificaciones ocurren siempre en todos
%~ los residuos objetivo de la modificación o bien de forma variable para que el
%~ motor de búsqueda considere también la masa del aminoácido sin modificación.
%~ }

%~ \item{
%~ Tipo de iones fragmento permitidos. 
%~ Los espectros de fragmentación teóricos son calculados a partir de las 
%~ secuencias de péptidos (trípticos) obtenidos de la base de datos de referencia. 
%~ Pero los tipos de fragmentos en un espectro MS/MS no son igualmente 
%~ abundantes sino que, en función del tipo de fragmentación,
%~ se generan más fragmentos de un tipo o de otro. 
%~ Así, en instrumentos de tipo cuadrupolo o híbridos \ac{QTOF},
%~ la fragmentación genera abundantes iones de la serie \emph{y-}, en las
%~ trampas iónicas además se producen igualmente abundantes iones \emph{b-}.

%Así, en instrumentos de tipo Trampa Iónica, Triple Cuadrupolo o
%híbridos Cuadrupolo-TOF la fragmentación genera abundantes iones de la
%series \emph{y-}, y \emph{b-}

%~ } 


%~ \end{itemize}

El establecimiento de estos valores tiene consecuencias muy notables en los
resultados de identificación de péptidos y en consecuencia de proteínas.
Por ejemplo, restingir a un rango de tolerancia muy pequeño el valor
posible de masa del precursor, aunque puede ser útil para obtener 
espectros de gran calidad en instrumentos muy sensibles, puede dejar 
fuera secuencias válidas. 

%También es posible 
%flexibilizar la especificidad de corte de la enzima proteolítica e 
%incluir una lista exhaustiva de posibles modificaciones post-traduccionales, 
%una aproximación utilizada en \citep{Creasy2002}
%Nota, esta referencia es una  especie de plugin para mascot


Una aproximación sensata puede consistir en
(disponiendo de recursos computacionales suficientes) realizar una búsqueda
muy abierta y posteriormente refinarla. %\citep{Creasy2002}
%Mirar 4.4.1 en NeszhviReview
En ocasiones se puede hacer una búsqueda con una ventana de tolerancia
amplia para la masa del precursor y posteriormente emplear ese parámetro
en el post-procesamiento (PeptideProphet, sección \ref{cap1:subsec:PeptideProphet})
de forma que se puede obtener un mayor rendimiento (en términos de
identificaciones para una cierta tasa de error) comparado con una búsqueda
para el mismo conjunto de espectros con una ventana más restrictiva \citep{Ding2008, Nesvizhskii2010}.

%-------------------------------------------------------------------
%-------------------------------------------------------------------


\phantomsection %para poder referenciarla en "Busqueda en bases de datos de secuencias"
\subsubsection*{Motores de búsqueda. Funciones de puntuación}
\label{cap1:subsubsec:motores de búsqueda}


%\textit{(mirar 3.1.2 Scoring functions en Neszvhi review en JOP)}
%\textit{(mirar Statistics for Proteomics course, J.Vazquez)}

Los motores de búsqueda se encargan de 
asignar a cada espectro empírico obtenido un péptido, el mejor candidato de una lista de los
posibles péptidos que han generado ese espectro, con una cierta medida
de puntuación función del grado de similitud entre espectro empírico y teórico. 
La estrategia general consiste en realizar una digestión teórica de las
secuencias de proteínas de referencia, teniendo en cuenta los parámetros especificados.
Así, para cada espectro observado, el motor de búsqueda recorre las secuencias 
en una base de datos (un archivo FASTA) seleccionando aquellos péptidos
con valores \mz similares al del ion precursor en el espectro empírico y
que se encuentran dentro del rango de tolerancia permitido obteniendo un
espectro teórico para cada uno. A continuación
se establece el grado de similitud de cada espectro adquirido con los espectros teóricos
de cada uno de los péptidos candidatos, es decir, se evalúa la calidad de cada PSM.

\figuraEx{Vectorial/spectrum_identification}{width=.99\textwidth}{fig:spectrum_identification}%
{Estrategia básica de identificación. Para el conjunto seleccionado de péptidos candidatos
se establece una correlación entre el espectro MS/MS empírico y el espectro generado teóricamente
por cada uno de los candidatos.}
{Estrategia básica de identificación}


Los motores de búsqueda realizan esta comparación de diferentes maneras,
usando distintas funciones de puntuación. Algunos incluso calculan más de
un tipo de puntuación. Existen una gran variedad de estrategias de puntuación
descritas profusamente en la bibliografía, basadas en funciones de
correlación entre espectros, basadas en contar el número de fragmentos compartidos,
en alineamiento de espectros o en el uso de reglas derivadas más complejas.


%SEQUEST%%% Mirar libro proteomics bioinformatics Capitulo Nesviz
SEQUEST \citep{Eng1994} fue la primera herramienta descrita para correlacionar
espectros MS/MS con secuencias de aminoácidos y actualmente sigue siendo
uno de los programas más utilizados. Para cada espectro adquirido, SEQUEST
calcula de manera independiente la puntuación de correlación (\emph{cross-correlation Score, Xcorr})
para todos los candidatos con los que es comparado.
En primer lugar se crea un espectro empírico procesado (espectro X) en el que los picos de baja 
intensidad son elimnados y el resto de valores \mz son redondeados al valor
entero más próximo. Para cada candidato se crea un espectro teórico (espectro Y)
usando unas reglas de fragmentación simplificadas. Entonces el valor \emph{Xcorr}
es calculado usando la función de correlación \emph{Corr(t)} (el producto 
entre los vectores X e Y, con Y desplazado \textit{t} unidades de masa 
respecto a X a lo largo del eje \mz ) (a)
\begin{equation}
\label{eq:sequest_corr}
\begin{split}
a)\ Corr(t) = \sum_{i} \ x_{i} \ y_{i+t}\\
b)\ Xcorr = Corr(0)\ - < Corr(t) >_{t}
\end{split}
\end{equation}
donde x\textsubscript{i} e y\textsubscript{i} representan los picos del espectro procesado
y el espectro teórico respectivamente.
Básicamente, \emph{Xcorr} contabiliza el número de fragmentos coincidentes
entre el espectro empírico (procesado) y el espectro teórico permitiendo
pequeños desplazamientos. %Además la puntuación se corrige sustrayendo el valor 
%medio de \textit{Corr(t)}, que representa una estimación del número de
%coincidencias aleatorias.
Además la puntuación se corrige sustrayendo el valor medio de \emph{Corr(t)} en torno a t = 0, que
representa una estimación de las coincidencias aleatorias entre picos (b).
SEQUEST también proporciona un valor de puntuación adicional, 
$\Delta$\emph{Cn}, que indica la diferencia entre el valor \emph{Xcorr}
del mejor candidato y el del segundo mejor candidato.
Ambos valores son por tanto indicativos de la calidad de cada \ac{PSM} que será
mejor cuanto más altas sean ambas puntuaciones.

%COMET%%%%
Una adaptación no comercial, de código abierto, del algoritmo original
de \mbox{SEQUEST} es el motor de búsqueda Comet \citep{Eng2013}, que introduce
la novedad de perimitir paralelizar el proceso de búsqueda para poder
ser ejecutado en procesadores multi-núcleo.

%VER COMET EN : Keller 2005 A uniform proteomics MS/MS analysis platform utilizing open XML file formats

%~ The score function within COMET is effectively the scalar dot product
%~ between two unit vectors representing the input spectrum and fragment 
%~ ion masses calculated from candidate sequences in the sequence database 
%~ (Field et al, 2002). The vectors are composed of approximately 1 Da mass
%~ bins (1.0005 for monoisotopic masses) to optimize the binning due to
%~ the periodicity in peptide isotopic masses (Parker et al, 2004). This 
%~ dot product score function allows for very fast calculations, as the 
%~ score is computed based on the simple summation of intensity values that 
%~ are accessed via a direct lookup of the mass index. However, in order to 
%~ be more sensitive than simply summing up matched peaks, as a regular dot 
%~ product effectively accomplishes, the input spectrum is preprocessed 
%~ such that intensities are modified as follows:

%X!TANDEM%%%
Otro motor de búsqueda frecuentemente utilizado es \emph{X!Tandem} \citep{Fenyo2003},
que calcula una puntuación llamada \emph{hyperscore}. Ésta también se basa
en contar el número de picos compartidos entre los espectros teórico y empírico,
pero en este caso, en la versión original del software, se tiene en cuenta si los iones coincidentes pertenecen
a las series \mbox{\emph{b-} e \emph{y-}.}



\begin{equation}
\label{eq:xtandem_hyperscore}
\begin{split}
by-Score &= \sum \ Intensidad\ picos\ coincidentes\ b\ e  y- \\
hyperscore &= (by-Score) \cdot N_{y}!\ \cdot N_{b}!
\end{split}
\end{equation}

Opcionalmente, X! Tandem puede ser modificado con la puntuación-k 
\citep{MacLean2006}, un producto escalar similar al implementado en 
Comet con una manipulación previa de las intensidades de los iones de
los espectros teóricos candidatos.

%OMSSA%%%
El motor de búsqueda \ac{OMSSA} \citep{Geer2004}, al igual que X!Tandem, es 
de código abierto. %Mirar libro MS data analysis in proteomics
En OMSSA, la puntuación es un reflejo del número de coincidencias entre
iones del espectro experimental y el teórico sin tener en cuenta si los
iones son de tipo \emph{b-} o \emph{y-}.

Tanto X!Tandem como OMSSA proporcionan una medida adicional además de
su propio método de puntuación, el \textit{e-valor}, que da idea de la
calidad de la asignación ya que puede interpretarse como el número
esperado de péptidos con puntuación igual o superior a la del mejor
péptido candidato.


%MASCOT%%%
Por último, \emph{Mascot} es quizás el más popular de los motores de búsqueda a 
pesar de ser comercial y de que el algoritmo de correlación que usa 
nunca fue publicado. El programa calcula una 
puntuación expresada en términos probabilísticos llamada \emph{ion score} 
que indica la probabilidad de que un número de coincidencias de picos
hayan ocurrido aleatoriamente dado el número total de picos en el espectro
y dada una distribución calculada de los valores \mz predichos para los candidatos 



%%COMET ?!
%\textit{COMET ?! Ya que se usa en PeptideAtlas2... nombrarlo al menos??}
%the probability of that number of matches occurring by chance given the
%number of peaks in the searched spectrum and the cumulative distribution of
%m/z values of predicted ions for all candidate peptides in the database. At the
%end, the probability that the match is random is converted into a more conven-
%ient scale by taking the logarithm. The ion score is less sensitive to such param-
%eters as the peptide molecular weight and the charge state of the precursor ion
%than Xcorr, but not completely independent. Unfortunately, the details of the
%Mascot scoring scheme remain unpublished, which prevents a comprehensive
%and independent assessment of this tool.
%A more recently developed database sea





%De forma general se pueden distinguir dos tipos de sistemas de puntuación
%de la calidad de una asignación péptido-espectro. Los sistemas en que 
%cada PSM se evalúa de forma independiente y aquellos 
%que cada PSM se sitúa en referencia a la distribución de muchas puntuaciones
%
%\medskip
%
%\emph{Puntuaciones basadas en factores paramétricos}.
%Para cada asignación péptido-espectro se establece una puntuación de 
%forma independiente.
%
%\medskip
%
%\emph{Puntuaciones basadas en distribuciones de espectro individual}.
%Este tipo de puntuación consiste en evaluar la distrubución de todas las
%puntuaciones de todos los péptidos candidatos que se comparan con cada
%espectro obtenido.
%
%\medskip
%
%\emph{Puntuaciones basadas en distribuciones promedio}. Estas puntuaciones
%analizan la distribución de las mejores puntuaciones de todos los espectros
%de un experimento.
%

%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\subsection{Otras estrategias de asignación péptido-espectro}
\label{cap1:subsec:otras estrategias de asignación péptido-espectro}
%\addcontentsline{toc}{subsection}{Otras estrategias de asignación péptido-espectro}






%-------------------------------------------------------------------
%-------------------------------------------------------------------

\phantomsection 
\subsubsection*{Búsqueda basada en bibliotecas de espectros}
\label{cap1:subsubsec:Búsqueda basada en bibliotecas de espectros}
 

Una alternativa posible a la búsqueda de espectros MS/MS usando espectros
teóricos predichos computacionalmente a partir de bases de datos de 
secuencias consiste en buscar mediante comparación directa con otros espectros
ya almacenados en una biblioteca de espectros. Estas bibliotecas se crean
mediante la recopilación de espectros MS/MS observados e identificados
en experimentos previos. 
Un nuevo espectro adquirido puede ser comparado directamente con los
espectros de la biblioteca (que se encuentren dentro de un rango de tolerancia
de masa permitida) y determinar así cual es la mejor coincidencia.

Al igual que en el caso de los motores de búsqueda basados en secuencia, 
existe un tipo específico de \textit{software} que permite crear 
bibliotecas de espectros y realizar búsquedas usándolas como SpectraST
\citep{Lam2007}.

Este tipo de aproximación supera a la búsqueda basada en secuencia en 
términos de velocidad, tasa de error y sensibilidad en la identificación
de péptidos \citep{Lam2007}
Además, a los resultados obtenidos también se les puede aplicar los 
modelos de validación estadística desarrollados para las búsquedas 
basadas en secuencia.

Sin embargo, en contrapartida, sólo es posible detectar aquellos péptidos
que hayan sido previamente identificados y que se encuentren en la 
biblioteca de espectros.

%-------------------------------------------------------------------
%-------------------------------------------------------------------

\phantomsection 
\subsubsection*{Identificación por secuenciación \textit{de novo}}
\label{cap1:subsubsec:búsqueda de novo}

%~ \figura{Vectorial/spectrum_interpret_from_man_to_auto_1}{width=.77\textwidth}{fig:spectrum_interpretation_1}%
%~ {Interpretación manual de espectros MS/MS. Secuenciación \textit{de novo}}


La secuenciación \textit{de novo} %(figura~\ref{fig:spectrum_interpretation_1}),
a diferencia de las otras aproximaciones
para interpretar espectros MS/MS, no requiere información adicional como
las secuencias de las proteínas o espectros recopilados en experimentos previos.
Por este motivo, las interpretación de espectros \textit{de novo} es útil
para detectar proteínas de organismos no secuenciados o procedentes de 
muestras de origen desconocido.

Existe también para este tipo de aproximación \textit{software} que
automatiza el proceso. Sin embargo su uso no se encuentra muy extendido
ya que, para la gran cantidad de espectros obtenidos en un experimento 
típico de \textit{shotgun}, el proceso es computacionalmente muy exhaustivo
y requiere espectros MS/MS de gran calidad.



%-------------------------------------------------------------------
%-------------------------------------------------------------------

%~ \phantomsection
%~ \subsubsection*{Búsqueda mediante etiquetas de secuencia}
%~ \label{cap1:subsubsec:Búsqueda mediante etiquetas de secuencia}
%~ 
%~ \textit{Mirar Hybrid approaches (3.4) en Nesvizhskii review,
%~ también -Computational and Statistical Analysis of Protein Mass Spectrometry Data- 
%~ de MacCoss}
%~ 
%~ \textit{
%~ Tag-based methods occupy an appealing middle ground between database search
%~ and de novo methods. Here, the basic idea is to use de novo analysis to 
%~ identify a collection of subpeptides (tags) that are hypothesized to occur
%~ in the sequence, and then extract candidates from a database that contain
%~ the tags. Tag-based methods can be quite fast, and retain the ability to
%~ partially identify spectra for which the corresponding peptide is not in
%~ the database
%~ }
%~ 
%~ \textit{
%~ Nesviz: -Hybrid approaches are particularly useful for the identification
%~ of post-translationally or chemically modified peptides-
%~ }

%-------------------------------------------------------------------
%-------------------------------------------------------------------

%~ \phantomsection
%~ \subsubsection*{Búsquedas tolerantes y multi-etapa}
%~ \label{cap1:subsec:Búsquedas tolerantes y multi-etapa}
%~ 
%~ \textit{Mirar Strategies for more comprehensive... (4) en Nesvizhskii review}


%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Evaluación estadística de resultados de identificaciones de péptidos y proteínas}
%\addcontentsline{toc}{section}{Evaluación estadística de identificaciones}
\label{cap1:sec:Evaluación estadística de los resultados}
%Esta parte de las distribuciones antes la tenia justo antes de las 
%funciones de puntuación , porque ahí hablo también de estas distribuciones


Frecuentemente en un solo experimento de proteómica \textit{shotgun}
se generan decenas de miles de espectros MS/MS. El procesamiento
bioinformático automatizado de estos datos es por tanto un aspecto 
fundamental para la interpretación de los resultados.
Por otra parte, no a todos los espectros MS/MS generados se
les asigna un péptido, y a su vez, de todo el conjunto de \ac{PSM} sólo
una fracción son correctos, es decir el espectro corresponde realmente a
la secuencia asignada. De hecho, en algunos experimentos realizados en instrumentos
de baja resolución, los \ac{PSM} incorrectos pueden llegar a suponer la mayoría \citep{Nesvizhskii2007a}.
Por eso, el desarrollo de métodos de evaluación de la calidad, en términos
de confianza estadística, es una tarea crucial para filtrar los resultados
generados. 
%Para hacer este tipo de análisis estadístico de los resultados
%es importante conocer la distribucion de puntuaciones de los péptidos 
%candidatos que pueden asignarse a cada espectro individual y, una vez seleccionado
%el mejor candidato, la distribucion de todas esas mejores puntuaciones de 
%todos los \ac{PSM} en el conjunto del experimento.


\subsection{Conceptos estadísticos básicos}

El planteamiento general en el tratamiento estadístico en experimentos 
de proteómica consiste en enfrentar dos hipótesis.
La hipótesis nula (H\textsubscript{0}) indica que el péptido (o proteína)
está incorrectamente identificado. La hipótesis alternativa (H\textsubscript{1})
indica lo contrario, que la asignación es correcta. 
Los tests estadísticos que se aplican enfrentan ambas hipótesis para aportar
una medida de probabilidad estadística, generalmente la probabilidad
de rechazar la hipótesis nula, es decir, de que la asignación sea correcta.
(Figura~\ref{fig:tabla_contingencia_estadistica_basica}).
La población que se estudia puede ser la puntuación de todos los candidatos
enfrentados a un espectro, o en términos globales, para todo un experimento,
las puntuaciones de todos los PSM.


En la tabla de contingencia de la figura~\ref{fig:tabla_contingencia_estadistica_basica},
U, V, T, y S corresponen a los Verdaderos Negativos, Falsos Positivos,
Falsos Negativos y Verdaderos Positivos respectivamente.
Con estos valores se pueden definir los conceptos de
\begin{itemize}
 \item\textit{sensibilidad} o tasa \ac{TPR}. Es la proporción
 de asignaciones consideradas correctas (por encima del umbral) entre el total de asignaciones correctas.
 \begin{equation}
  \label{eq:sensibilidad}
  TPR = \frac{S}{T+S}
 \end{equation}

\item\textit{especificidad}. Es la proporción
 de asignaciones consideradas incorrectas entre el total de asignaciones incorrectas.
 \begin{equation}
  \label{eq:especificidad}
  especificidad = \frac{U}{U+V}
 \end{equation}

\item Tasa  \ac{FNR}. Es la proporción
 de asignaciones consideradas incorrectas entre el total de asignaciones correctas.
 \begin{equation}
  \label{eq:FNR}
  FNR = 1 - sensibilidad = \frac{T}{T+S}
 \end{equation}

\item Tasa  \ac{FPR}. Es la proporción
 de asignaciones consideradas correctas entre el total de asignaciones incorrectas.
 \begin{equation}
  \label{eq:FPR}
  FPR = 1 - especificidad = \frac{V}{U+V}
 \end{equation}

\item Tasa  \ac{FDR}. Es la proporción
 de asignaciones consideradas incorrectas entre el total de asignaciones consideradas (por encima del umbral).
 \begin{equation}
  \label{eq:FDR}
  FDR = \frac{V}{S+V}
 \end{equation}


\end{itemize}
\figuraEx{Vectorial/tabla_contingencia_estadistica_basica}{width=.99\textwidth}{fig:tabla_contingencia_estadistica_basica}%
{Tabla de contingencia. Contraste de hipótesis. La estrategia general
consiste en realizar tests que permitan rechazar la hipótesis nula y por
tanto tener un criterio estadístico para aceptar la hipótesis alternativa,
es decir, afirmar que la asignación es correcta.}
{Tabla de contingencia. Contraste de hipótesis}


\subsection{Puntuaciones basadas en distribuciones de espectro individual y promedio}

\subsubsection*{Distribución de espectro individual}

Generalmente los motores de búsqueda aportan varios tipos de puntuación para
cada PSM. Un tipo de puntuaciones se refiere a la calidad de cada asignación 
en particular, evalúa el grado de similitud entre el espectro empírico y 
el péptido asignado, el mejor de la lista de candidatos.
(\emph{Xcorr} en SEQUEST, \emph{hyperscore} en X!Tandem o \emph{ionScore} en Mascot).
Pero además, a veces, aportan una puntuación indicativa de la calidad del PSM en relación a otros,
al segundo mejor candidato ($\Delta$\emph{Cn} de SEQUEST); o con respecto
a una población del resto de candidatos que obtuvieron puntuaciones inferiores 
utilizando los parámetros estadísticos \emph{e-valor} y \emph{p-valor}.

Para ello, en primer lugar se selecciona el mejor péptido asignado a un 
espectro, es decir aquel candidato con la mejor puntuación, y a continuación
se construye una distribución de las puntuaciones del resto de péptidos 
comparados con el espectro. Esta distribución 
representa la hipótesis nula, la población de asignaciones \ac{PSM} incorrectas.

%\figura{Vectorial/pvalue_estimation}{width=.95\textwidth}{fig:pvalue_estimation}%
%{Estimación del p-valor}

El \emph{p-valor} se calcula 
entonces relacionando la puntuación del mejor péptido con respecto a esta
distribución (aleatoria) del resto de puntuaciones. Cuanto más alejada 
se sitúa la mejor puntuación del centro de la distribución %que representa la hipótesis nula 
mayor es la significatividad estadística del PSM.% la asignación péptido-espectro.
El \emph{p-valor}, es por tanto, una medida de la probabilidad 
% de observar por azar un PSM con una cierta puntuación o mayor (asumiendo que se cumple la hipotesis nula
de que el mejor péptido candidato seleccionado sea asignado incorrectamente al espectro.
Así, un \emph{p-valor} bajo indicará una baja probabilidad de que el
\ac{PSM} haya sido asignado de forma incorrecta, es decir, es probablemente correcto.

El \emph{e-valor} también se usa frecuentemente como medida de calidad
en aproximaciones de espectro individual. Esá relacionado con el \emph{p-valor}
pero se interpreta como el número esperado de péptidos con puntuación
igual o superior a la del mejor péptido candidato. 
X!Tandem calcula un \emph{e-valor} obtenido empíricamente a partir de la distribución
de espectro individual para cada PSM (Figura~\ref{fig:evalue_estimation})

\figuraEx{Vectorial/evalue_estimation}{width=.90\textwidth}{fig:evalue_estimation}%
{Para estimar el e-valor, X!Tandem  convierte a escala logarítmica la 
distribución de espectro individual utilizando su puntuación (\textit{hyperscore}) y 
a continuación, interpola, en la recta ajustada, (que representa el número de asignaciones
aleatorias esperadas) el valor que correspondería a la mejor puntuación obtenida.}
{Estimación del e-valor}


Ambos parámetros estadísticos, el \emph{p-valor} y el \emph{e-valor},
a diferencia del valor de puntuación original calculado por el motor de búsqueda,
son independientes de la función de puntuación utilizada y por tanto 
suponen una medida más general de la calidad de cada \ac{PSM} y son comparables
en ensayos que usan distintos instrumentos, diferentes motores de búsqueda y parámetros
\citep{Nesvizhskii2010}.

%\todo{ O NO Exactamente, ambos p y e val son probab que el psm sea incorrecto
%y la poblacion de psms incorrecta sí depende del experimento. Para eso está 
%el discriminant score y la prob de peptprophet que sí es una medida de que el psm sea correcto
%y es por tanto independiente del experimento. Ver ppt Interpreting }


Algunos motores de búsqueda, además de su función de puntuación propia,
como \textit{hyperscore} en el caso de \textit{X!Tandem} o \textit{ion score}
en el caso de \textit{Mascot} también hacen uso de una distribución de
espectro individual para calcular y proporcionar un \textit{e-valor} para cada PSM. 


\medskip{}


\subsubsection*{Distribución promedio}

En los experimentos \textit{shotgun} generalmente se obtienen miles de espectros MS/MS.
Las medidas estadísticas de las distribuciones de espectro individual
por tanto, no son suficientes.
Incluso en el caso de que se requiera
un \emph{p-valor} muy bajo, (lo que implicaría una confianza estadística muy alta
para un \ac{PSM} en concreto) si se evalúan miles de espectros MS/MS podrían 
ocurrir \ac{PSM} con \mbox{\emph{p-valores}} igualmente bajos sólo por azar. Por este
motivo se utilizan estrategias de \emph{corrección de test múltiple} 
(\emph{multiple test correction}) que re-ajustan los \mbox{\emph{p-valores}}.
Una aproximación muy utilizada, aunque produce resultados conservadores,
  es la corrección de Bonferroni \citep{Abdi2007}, que simplemente
divide el \mbox{\emph{p-valor}} por el número de veces que se repite el test.
Así para un \ac{PSM} con \mbox{\emph{p-valor} = 0,05} en un experimento en el que hay
otros 10.000 \ac{PSM}, el \mbox{\emph{p-valor}} original habría de reajustarse a
0,05/10.000 = 5·10\textsuperscript{-6}.

\figuraEx{Vectorial/single_spectrum_and_average_distributions}{width=1\textwidth}{fig:single_spectrum_and_average_distributions}%
{La distribución de espectro individual es la distribución de las puntuaciones
de todos los péptidos candidatos comparados con el espectro empírico. La
distribución promedio, es la distribución de las puntuaciones de los mejores candidatos 
para el total de todos los espectros empíricos. Ésta se puede considerar una población
mixta compuesta por una mezcla de subpoblación de asignaciones incorrectas y otra subpoblación
de asignaciones correctas.}
{Distribuciones de espectro individual y promedio}

Las distribuciones promedio, como muestra la Figura~\ref{fig:single_spectrum_and_average_distributions}, 
son distribuciones de las mejores puntuaciones
de todos los \ac{PSM} de un experimento y permiten por tanto estimar otros parámetros
estadísticos adicionales a nivel global, como la Tasa de Falsos Descubrimientos, FDR
y la probabilidad de un PSM en particular en el contexto global del experimento.

\medskip

Es importante destacar que las aproximaciones que usan distribuciones de
espectro individual son compatibles con las que usan distribuciones promedio,
es decir, se puede realizar un análisis FDR global para un conjunto de
\ac{PSM} que han sido ordenados por \textit{p-valores} o \textit{e-valores} obtenidos individualmente.




\subsection{Bases de datos señuelo y Tasa de Falsos Descubrimientos (FDR)}

El tipo de evaluación estadística más ampliamente utilizada en experimentos
de proteómica \textit{shotgun} es un tipo de corrección de test múltiples, 
la \emph{Tasa de Falsos Descubrimientos (FDR, False Discovery Rate)} \citep{Benjamini1995}.
Básicamente, el concepto de tasa FDR se refiere a la proporción de \ac{PSM} incorrectos
que se aceptan en todo el conjunto de \ac{PSM} de un experimento para un umbral
de puntuación (o de parámetro estadístico como el \emph{p-valor}) fijado.

Para la estimación de la tasa FDR (Figura~\ref{fig:single_spectrum_and_average_distributions}),
la estrategia utilizada consiste
esencialmente en utilizar una base de datos llamada \emph{señuelo} 
o \emph{decoy} (Figura~\ref{fig:target_and_decoy_dbs}) \citep{Elias2007}.
Es una aproximación sencilla pero efectiva que requiere que los espectros MS/MS
sean comparados con espectros teóricos derivados de secuencias \emph{señuelo},
que pueden ser generadas de varias formas pero que, en cualquier
caso, son secuencias que no existen, no corresponden a ninguna proteína.
La asignación de espectros MS/MS a
estas secuencias \emph{señuelo} permite %es % permiten %por tanto
recrear una hipótesis nula. Se puede tener la certeza de que los resultados 
de identificaciones correspondientes a secuencias \emph{señuelo}, claramente 
etiquetadas en el fichero fasta, son identificaciones incorrectas.
A continuación, para hacer las búsquedas, se puede añadir a la base de 
datos de secuencias \emph{reales} (secuencias \emph{target})
un número equivalente de secuencias \emph{señuelo} y hacer que el motor de búsqueda
use esta base de datos concatenada (\emph{secuencias \emph{reales} - secuencias \emph{señuelo}})
del doble de tamaño que la original.
O bien se pueden realizar dos búsquedas consecutivas, una utilizando la
base de datos de secuencias \emph{reales} y otra a continuación utilizando
la de secuencias \emph{señuelo}.

\figuraEx{Vectorial/target_and_decoy_dbs}{width=.99\textwidth}{fig:target_and_decoy_dbs}%
{Una estrategia comúnmente empleada en la construcción de bases de datos
señuelo consiste en barajar la secuencia aminoacídica, péptido a péptido 
(para así conservar el tamaño medio de los péptidos), de cada una de las 
proteínas en la base de datos original, para obtener así una base de datos
señuelo, y a continuación concatenarlas.}
{Construcción de una base de datos señuelo}

%VER Target-Decoy Search Strategy for Mass Spectrometry-Based Proteomics Elias, Gygi 2010 M Mol Bio
Las secuencias \emph{señuelo} pueden obtenerse mediante
varios métodos \citep{Elias2007,Kall2008}
La inversión de la secuencia de la proteína es un método sencillo que 
conserva la frecuencia media de cada aminoácido y permite generar siempre
las mismas secuencias \textit{señuelo} para sucesivas búsquedas. A cambio, 
el hecho de que no sea un orden aleatorio puede implicar
que la población \textit{señuelo} no refleje exactamente una hipótesis nula.
También se pueden generar las secuencias de cada proteína de forma aleatoria.
Esto también conserva las frecuencias de los aminoácidos, pero por otra parte,
se elimina toda redundancia y se generarán por tanto un mayor número de 
péptidos \textit{señuelo}.
Otra opción es, en lugar de generar nuevas secuencias para cada proteína,
crear péptidos \textit{señuelo} de cada proteína dado el patrón de corte
conocido de la enzima proteolítica utilizada. Esta opción tiene la ventaja
de que los péptidos creados serán el mismo número y tendrán exactamente 
las mismas masas que las secuencias \emph{reales}.


%El objetivo de la creación  
%Con la hipótesis nula que proporcionan las asignaciones a secuencias \textit{señuelo}
Una vez establecida esta hipótesis nula, la estrategia asume una idea básica central:
la frecuencia con que los espectros MS/MS son asignados a secuencias 
\emph{señuelo} sigue la misma distribución que la frecuencia con que los
espectros son asignados incorrectamente a secuencias \emph{reales}. 

Así, de forma general y dado que las bases de datos de secuencias 
\emph{reales} y \textit{señuelo}
tienen el mismo tamaño, el número de \ac{PSM} incorrectos o Falsos Positivos
(N\textsubscript{inc}, aquellos espectros a los que se ha asignado
incorrectamente una secuencia \emph{real})
puede ser considerado equivalente al número de \ac{PSM} \emph{señuelo} 
(N\textsubscript{d}, espectros a los que se ha asginado una secuencia \emph{señuelo}).
Con esto se puede estimar la tasa FDR como
 N\textsubscript{d}/N\textsubscript{t},
esto es, la proporción de \ac{PSM} \textit{señuelo}, N\textsubscript{d} como sustituto
conocido de N\textsubscript{inc}, 
entre el total de secuencias \emph{reales} con puntuaciones superiores
al umbral fijado, N\textsubscript{t}. 
En ocasiones, cuando las búsquedas se hacen sobre la base de datos concatenada,
para tener en cuenta que el tamaño es el doble que la original,
la tasa FDR también puede calcularse como 
2N\textsubscript{d}/(N\textsubscript{t}+N\textsubscript{d})

Esta estimación general puede tener variantes.
En el caso de que se realicen dos búsquedas independientes, una sobre
la base de datos \textit{target} y a continuación sobre la equivalente \textit{señuelo},
la estimación de FDR como 
N\textsubscript{d}/N\textsubscript{t}
resulta conservadora ya que N\textsubscript{d} puede considerarse una sobre-estimación
de N\textsubscript{inc}. Esto se debe a que toda la población de espectros
se compara con las secuencias \textit{señuelo} a pesar de que algunos de los
espectros podrían asignarse correctamente a una secuencia \textit{target}.
Además, la mayoría de las funciones de puntuación tienden a otorgar
puntuaciones más altas a \ac{PSM} \textit{señuelo} que a \ac{PSM} \textit{target}
incorrectos %\citep{Navarro2009a}
por lo que la distribución de puntuaciones
\textit{señuelo} no es un reflejo preciso de la distribución de puntuaciones
de los \ac{PSM} incorrectos.
Una forma de corregir este efecto consiste en estimar una aproximación 
previa de la fracción N\textsubscript{inc} dentro de N\textsubscript{t} 
considerando que la mayoría de los \ac{PSM} con puntuaciones bajas son 
probablemente incorrectos \citep{Kall2008}
Así se puede incluir en la tasa FDR un factor de corrección definido
por el porcentaje estimado de \ac{PSM} \textit{target} incorrectos (PIT): Si en 
N\textsubscript{t} el 80\% de los \ac{PSM} son incorrectos, la tasa FDR 
calculada como N\textsubscript{d}/N\textsubscript{t} se multiplica por 0.8
para obtener un valor FDR más preciso (Por cada 100 \ac{PSM} \textit{señuelo}
en el conjunto de \ac{PSM} aceptado se estiman 80 \ac{PSM} \textit{target} incorrectos) 


Las búsquedas utilizando una base de datos concatenada 
\textit{target-decoy} son menos sensibles al efecto de sobre-estimación de 
N\textsubscript{d}, sin embargo también producen un resultado FDR conservador.
En este caso ya no se compara todo el conjunto de espectros con las 
secuencias \textit{target} y \textit{señuelo} por separado sino simultáneamente
lo que produce un efecto de competición.
Se puede considerar que las secuencias \textit{target} y \textit{señuelo}
compiten por el espectro.
Pero esto implica que a algunos espectros se les puede asignar una secuencia
señuelo con una puntuación mayor a la que se obtiene al asignarles la
secuencia \textit{target} correcta. En tal caso se produce un aumento 
de N\textsubscript{d} y una consiguiente reducción del
número de \ac{PSM} correcto y por tanto un incremento de FDR.


Otra forma de mejorar la estimación de FDR es un algoritmo refinado \citep{Navarro2009a}
que consiste en una búsqueda en bases de datos separadas
teniendo en cuenta en conjunto las distribuciones
de poblaciones de \ac{PSM} \textit{target} y \ac{PSM} \textit{decoy} y corrige
el efecto de competición de las búsquedas en bases de datos concatenadas.




%\textit{
%IMPORTANTE:
%Mencionar MAYU, explicar en que consiste un poquito por lo menos
%(Y quiza tambien Percolator
%}




\subsection{Modelos mixtos de probabilidad. \mbox{Probabilidad posterior}}
\label{cap1:subsec:PeptideProphet}

%Modelos mixtos de evaluación de la confianza estadística

La estrategia de las bases de datos señuelo permite una estimación global
de la tasa FDR pero no proporciona un valor de confianza estadística para 
cada \ac{PSM} individual. % en el conjunto de todos los PSMs del experimento.

PeptideProphet \citep{Keller2002} es un algoritmo de post-procesamiento
(empleado después de que el motor de búsqueda haya establecido una lista 
de PSM), el primero en implementar este tipo de análisis,
que permite estimar la confianza en los péptidos identificados 
aportando un valor de probabilidad posterior.

Resumidamente, PeptideProphet recalcula las puntuaciones y emplea un 
método de Bayes empírico -un procedimiento de inferencia estadística en 
que la distribución \textit{a priori} se estima a partir de los datos-
para establecer un modelo mixto de probabilidad que integra las subpoblaciones
de espectros correctamente asignados e incorrectamente asginados.

Primero, PeptideProphet recalcula las puntuaciones. Mediante análisis
discriminante, las distintas puntuaciones aportadas por un motor de búsqueda
son combinadas en un solo valor que maximiza la separación de asignaciones 
correctas e incorrectas.
La puntuación discriminante \emph{S} resulta de una función combinación ponderada
de las puntuaciones \textit{x\textsubscript{1}}, \textit{x\textsubscript{2}}, ..., \textit{x\textsubscript{s}}
expresada de forma general:

\begin{equation}
\label{eq:discriminant_function_general}
S = F(x_{1}, x_{2},...,x_{S}) = c_{0} + \sum_{i=1}^S \ c_{i}x_{i}
\end{equation}

donde la constante \textit{c\textsubscript{0}} y el peso de las variables 
\textit{c\textsubscript{i}} son derivadas de forma
que la proporción de la variación entre clases (asignaciones correctas
e incorrectas) se maximiza con respecto
a la variación dentro de cada clase.

Y como ejemplo específico para el caso de SEQUEST:

\begin{equation}
\label{eq:discriminant_function_sequest}
S = F_{SEQUEST}(Xcorr, \Delta C_{n}, SpRank) = c_{0} + c_{1}Xcorr, + c_{2}\Delta C_{n} + c_{3}SpRank\\
\end{equation}

Aunque en su versión original, el \textit{software} requería una población de asignaciones
correctas de referencia para estimar estas variables, posteriormente
el algoritmo fue extendido para poder estimar los coeficientes de forma 
dinámica a partir de los datos en cada experimento \citep{Ding2008,Ma2012}.

PeptideProphet asume que la distribución de las puntuaciones
recalculadas \textit{S} puede explicarse como una combinación, una 
distribución mixta, en la que las asignaciones realmente correctas siguen
una distribución \textit{Normal}($\mu$, $\sigma$), y las asignaciones incorrectas,
una distribución \textit{Gamma}($\alpha$, $\beta$, $\gamma$). 
(Figura~\ref{fig:PeptideProphet_fit_2_a_dataset_of_D_scores}).

\figuraEx{Vectorial/PeptideProphet_fit_2_a_dataset_of_D_scores}{width=0.88\textwidth}{fig:PeptideProphet_fit_2_a_dataset_of_D_scores}%
{PeptideProphet considera la distribución promedio de PSMs como una mezcla
de una subpoblación de PSM correctos (distribución Normal, en verde) 
y otra de PSM incorrectos (distribución Gamma, en rojo). Una vez inferidas
estas distribuciones mediante el algoritmo \textit{EM}, la probabilidad
de un PSM en particular puede calcularse mediante el teorema de Bayes
como la probabilidad de tener una puntuación siendo correcto con respecto
a la probabilidad de tener esa puntuación. }
{Modelo mixto de probabilidad. PeptideProphet}



Pero además de la puntuación discriminante hay otros parámetros que 
contribuyen a la separación de las poblaciones de PSM incorrectos y PSM correctos.
Concretamente  los parámetros \ac{NTT}, \ac{NMC} y el error en la masa del precursor, $\Delta$M,
tienen individualmente distribuciones diferentes
para las asignaciones correctas e incorrectas \citep{Choi2008} lo que aporta una 
mejor definición de las distribuciones cuando son incorporados en un modelo mixto común.

A continuación, PeptideProphet usa un algoritmo 
\ac{EM} y el teorema de Bayes para estimar las distribuciones \textit{Normal}, de PSM
correctos, y \textit{Gamma}, de PSM incorrectos; y calcular una probabilidad 
para cada asignación individual.

Para iniciar, el algoritmo require los parámetros $\pi_{0}$ (la proporción
de asignaciones incorrectas en toda la población); $\mu$, $\sigma$, parámetros
que definen la \textit{Normal}; y $\alpha$, $\beta$, $\gamma$, que definen la \textit{Gamma}.

En el primer paso -\textit{E}- se usa el teorema de Bayes para estimar la probabilidad
condicionada de cada puntuación de ser correcta: 

\begin{equation}
\label{eq:bayes_prob}
P(+|S) = \frac{P(S|+)P(+)}{P(S|+)P(+)\ +\ P(S|-)P(-)} 
\end{equation}

\bigskip{}
donde \textit{P(+|S)} es la probabilidad de que el PSM con puntuación S
sea correcta, \textit{P(S|+)} y \textit{P(S|-)} son las probabilidades 
condicionadas de una puntuación \textit{S} entre las distribuciones correctas e
incorrectas; y \textit{P(+)} y \textit{P(-)} son las probabilidades
\textit{a priori} de asignaciones correctas e incorrectas
(Figura~\ref{fig:PeptideProphet_fit_2_a_dataset_of_D_scores}).
Esta probabilidad puede entenderse como %la proporción de la la densidad de
%\textit{Gamma} escalada por $\pi_{0}$ con respecto a la suma de las densidades
%\textit{Gamma} y \textit{Normal} escaladas $\pi_{0}$ y 1 - $\pi_{0}$ 
%para una puntuación \textit{S}.
%O dicho de otra manera,
la probabilidad de que, teniendo una puntuación 
\textit{S}, una asignación sea correcta con respecto a la probabilidad
de tener esa puntuación. 
De la misma manera se puede calcular la probabilidad de ser incorrecta. En ese caso,  
el valor es la Probabilidad de Error Posterior, \textit{PEP}
que coincide con la FDR local.

Y en el siguiente paso -\textit{M}-, una vez calculadas las probabilidades 
de cada PSM se recalculan los valores de los parámetros que describen las distribuciones.

Los pasos \textit{E} y \textit{M} se suceden iterativamente hasta la 
convergencia, el momento en que los parámetros estimados no difieren 
en valor absoluto de un error predefinido suministrado, $\epsilon$.

Además de proporcionar probabilidades para cada PSM, PeptideProphet 
también calcula la FDR global. 
Para un umbral de puntuación \textit{t}:

\begin{equation}
\label{eq:fdr_with_peptideprophet}
FDR(t) = \frac{P(-)P(S>t\ |-)}{P(S>t\ |-)P(-)\ +\ P(S>t\ |+)P(+)} 
\end{equation}

\bigskip{}

y otros parámetros como \textit{p-valor} y la tasa de falsos positivos 
\ac{FPR}. (Figura~\ref{fig:PeptideProphet_fit_2_a_dataset_of_D_scores}).

En un principio, cuando fue implementado \citep{Keller2002}, este modelo mixto para el
 cálculo de probabilidades no hacía uso de búsquedas realizadas usando
la estrategia de las secuencias \textit{señuelo} pues no se había generalizado aún.
Cuando comenzaron a emplearse este tipo de búsquedas PeptideProphet incorporó
esta información haciendo que las puntuaciones correspondientes a péptidos
\textit{señuelo} sólamente puedan contribuir a la estimación de los
parámetros que describen la distribución \textit{Gamma} de PSM incorrectos.
Esto permitó redefinir una versión semisupervisada del algoritmo \citep{Choi2008}
en el sentido de que la clase (PSM correctos o incorrectos) pasa a ser un parámetro
conocido para algunas pero no todas las asignaciones.

%\textit{The Probability Ratio Method, Navarro et al}



%-------------------------------------------------------------------
%-------------------------------------------------------------------


%\phantomsection
\section{Inferencia de proteínas a partir de péptidos}
%\addcontentsline{toc}{section}{Inferencia de proteínas a partir de péptidos}
\label{cap1:sec:Inferencia de proteínas a partir de péptidos}

%\todo{Mirar paper de Aebersold:
%Interpretation of shotgun proteomic data: the protein inference problem}

%\todo{Y mirar también ProteinProphet}

En un experimento de proteómica \textit{shotgun}, desde el momento de la digestión
de las proteínas, todo el análisis subsiguiente se realiza a nivel de
péptidos. Esto, que permite que la estrategia \textit{shotgun} pueda
obtener un alto rendimiento en la identificación de péptidos, sin embargo
provoca una dificultad adicional para ensamblar una lista de proteínas
que presumiblemente se encuentran en la muestra analizada.



Uno de los principales motivos que complican la inferencia de las proteínas 
se refiere a la pérdida de la correspondencia péptido-proteína como consecuencia 
fundamentalmente de la detección de péptidos compartidos o \textit{degenerados}
cuyas secuencias están en diferentes proteínas. Esta dificultad, descrita
como parte del \textit{problema de la inferencia de proteínas} en \citep{Nesvizhskii2005},
a su vez se deriva de varios posibles escenarios. En algunos casos
el procesamiento alternativo de intrones provoca la existencia de isoformas
de una porteína en la muestra. De éstas, sólo algunas tienen en su 
secuencia péptidos trípticos exclusivos que permitan, en caso de 
ser detectados, concluir la presencia de la proteína fehacientemente. 
En otros casos, proteínas diferentes procedentes
de una familia de genes (parálogos) poseen una alta homología de secuencia.
Frecuentemente, a pesar de detectar un cierto número de péptidos, no se 
puede asumir la presencia de ninguna de las proteínas de la familia en particular.

En función de la presencia de estos péptidos compartidos y de péptidos 
exclusivos de cada proteína se han descrito métodos y nomenclaturas
adecuadas para definir como \textit{identificada} una proteína o lista de proteínas
\citep{Nesvizhskii2005, Prieto2012}

%\textit{Citar aquí PAnalyzer Gorka y cía, los distintos tipos de grupos}


\figuraEx{Vectorial/protein_inference_non_random_peptide_grouping}{width=.99\textwidth}{fig:protein_inference_non_random_peptide_grouping}%
{Agrupamiento no aleatorio de péptidos en proteínas. Los péptidos
correctamente asignados generalmente se agrupan formando parte de una proteína,
sin embargo esto no ocurre para las asignaciones incorrectas, cada PSM incorrecto 
corresponde a una proteína diferente y se traduce por tanto en una identificación de proteína errónea.
(1 PSM incorrecto, 1 proteína incorrecta). }
{Agrupamiento no aleatorio de péptidos en proteínas}

Un principio básico que ha sido muy utilizado es el de la llamada navaja
de Occam \citep{Nesvizhskii2003} consiste en presentar el menor número 
posible de proteínas que pueda explicar todos los péptidos observados y,
en el caso de que varias proteínas estén representadas por varios péptidos
compartidos (ninguno de ellos exclusivo de una proteína), presentar las
proteínas en un grupo como una sola entrada de la lista.

Otra de las dificultades en la inferencia de proteínas es el fenómeno
consistente en el agrupamiento dirigido de péptidos en sus correspondientes 
proteínas, lo que provoca una amplificación de las tasas de eror. Como
se observa en la figura \ref{fig:protein_inference_non_random_peptide_grouping},
mientras que las identificaciones de péptidos correctas tienden a agruparse
en un número pequeño de proteínas, los péptidos incorrectos, puesto que 
proceden de asignaciones aleatorias a entradas en la base de datos, suponen
una proteína errónea por cada péptido.

Para combinar los péptidos en las proteínas originarias se pueden realizar
varias aproximaciones. La más sencilla consiste en seleccionar de todos 
sus PSM el de mejor puntuación o probabilidad y usarlo como puntuación
de la proteína. Sobre este método básico se puede añadir además reglas
como que al menos dos péptidos que superen un cierto umbral de puntuación
deben contribuir a la inferencia de la proteína. A menudo se emplean 
variaciones de este método, fijando distintos umbrales y criterios, sin
embargo una aproximación estadística puede ser más interesante,
utilizando las probabilidades a nivel de PSM para combinarlas y obtener
una probabilidad a nivel de proteína.
La herramienta ProteinProphet \citep{Nesvizhskii2003} implementa este tipo
de análisis. 

De forma general se podría calcular la probabilidad de una proteína P
como 1 menos las probabilidades de ser incorrectos de cada uno (\textit{p\textsubscript{i}})
 de sus péptidos:

\begin{equation}
\label{eq:ProteinProphet1}
P(prot) = 1 - \prod_{i}(1 - p_{i})\\
\end{equation}

Pero ProteinProphet refina las probabilidades de cada PSM previamente
a combinarlas para tener en cuenta el problema del agrupamiento dirigido
de péptidos en proteínas descrito, especialmente importante en proteínas
representadas por un solo péptido. Este reajuste inicial consiste en tener
en cuenta el parámetro \ac{NSP}, de forma que se
penalizan las probabilidades de péptidos cuando sólo uno aporta evidencia
para una proteína mientras que las probablidades se reajustan aumentándose
en casos en que muchos péptidos hermanos aporten evidencia a la presencia de la proteína. 

El reajuste teniendo en cuenta el \ac{NSP} se realiza con una
aproximación de Bayes empírica análoga a los modelos de PeptideProphet
que estima las distribuciones de NSP entre las poblaciones de péptidos 
correcta e incorrecta:

\begin{equation}
\label{eq:ProteinProphet2}
\begin{split}
NSP_{i} &= \sum_{j\not=i}p_{j}\\
p'_{i} &= \frac{p_{i}\ f_{1}(NSP_{i})}{p_{i}\ f_{1}(NSP_{i})+(1-p_{i})\ f_{0}(NSP_{i})}\\
\\
P(prot) &= 1 - \prod_{i}(1 - w_{i}^{n} p_{i}')
\end{split}
\end{equation}

donde \textit{f\textsubscript{0}(NSP)} y \textit{f\textsubscript{1}(NSP)}
son las distribuciones NSP entre los peptidos incorrectos y correctos, p$'$\textsubscript{i} 
es la probabilidad ajustada para el péptido \textit{i}, y w\textsubscript{i}\textsuperscript{n} el peso del péptido i en la proteína n.

Pero además de reajustar las probabilidades de los PSM teniendo en cuenta
el agrupamiento no aleatorio de péptidos en proteínas, ProteinProphet también
considera la existencia de péptidos presentes en más de una proteína. Para ello otorga
pesos de forma que la contribución de un péptido cuya secuencia está presente
en varias proteínas 

%\phantomsection
\section{Herramientas adicionales de post-procesamiento y validación a nivel de péptido y proteína}
%\addcontentsline{toc}{section}{Inferencia de proteínas a partir de péptidos}
\label{cap1:sec:Herramientas adicionales de post-procesamiento}

Algunas herramientas bioinformáticas de post-procesamiento de resultados
de identificaciones como PeptideProphet y ProteinProphet han demostrado
ser de gran utilidad proporcionando un medio de calcular probabilidades
y tasas de error de forma muy precisa. 
Sin embargo, la modelización que
emplean a veces no resulta muy eficiente, especialmente en casos de 
listas de espectros e identificaciones muy grandes \citep{Reiter2009}.

Por otra parte, frecuentmente interesa desde el punto de vista experimental,
alcanzar una cobertura lo más amplia posible del proteoma objeto de estudio
utilizando para ello una aproximación combinada con varios motores de búsqueda.

%iProphet
La herramienta de \textit{software} iProphet \citep{Shteynberg2011} fue
desarrollada para resolver este tipo de necesidades, implementando un
modelo más completa de todas las fuentes de información en un 
experimento de proteómica \textit{shotgun}. Si PeptideProphet aporta
probabilidades a nivel de PSM, esta extensión refina las probabilidades
aportándolas a nivel de secuencia peptídica única, es decir combina todas
las probabilidades de los PSM que se refieren a la misma secuencia.
Para ello, el programa reajusta (mejorando o penalizando) los valores de
salida de PeptideProphet(de forma análoga a como ProteinProphet lo hace 
con el parámetro NSP) usando cinco fuentes adicionales de información
proporcionadas por los parámetros
 \ac{NSS}, que aumenta las probabilidades de una
secuencia peptídica si es identificada por múltiples motores de búsqueda;
\ac{NRS}, que tiene en cuenta si hay muchos espectros que son asignados a la misma secuencia con alta probabilidad;
\ac{NSE}, que aumenta las probabilidades de péptidos
que son repetidamente identificados a partir de espectros obtenidos en 
distintos experimentos (asumiendo que son réplicas o protocolos similares);
\ac{NSI}, que aumenta la probabilidad
de un péptido si es encontrado en distintos estados de carga; 
y por último, \ac{NSM}, que actúa de forma similar
a NSI, aumenta la probabilidad si se encuentra una instancia modificada
y sin modificar de un péptido. 

%MAYU:
Por otra parte, las herramientas hasta ahora descritas para el control de 
la tasa de errores, ya sea mediante la estrategia de búsqueda en bases 
de datos señuelo o bien con el control estadístico que aportan los modelos 
mixtos de probabilidad (PeptideProphet), permiten controlar la tasa FDR
a nivel de PSM. Sin embargo obtener los valores de FDR a nivel de proteína
implica un nivel adicional de complejidad. Dado que una proteína se 
considera identificada cuando contiene un conjunto de PSM que a su vez
pueden ser correctos o no, el error, como muestra la figura 
\ref{fig:protein_inference_non_random_peptide_grouping}, se propaga
de forma especialmente acusada en experimentos que generan grandes conjuntos
de datos (decenas de miles de espectros) \citep{Reiter2009}. 
Por eso la estimación de FDR a nivel de proteína ha de tener en cuenta que
los PSM falsos positivos y los PSM verdaderos positivos tienen distribuciones
diferentes. Mientras que los primeros apuntarán aleatoriamente a entradas
de toda la base de datos, los segundos solo corresponden al subconjunto de
proteínas presentes en la muestra. Esto hace que en la práctica las tasas
de error para proteínas sean mayores que para PSM.


%~ \begin{itemize}
%~ \item Numero de búsquedas \textit{hermanas}, \ac{NSS}. Este modelo aumenta
%~ las probabilidades de una cierta secuencia peptídica si es identificada
%~ múltiples veces con distintos motores de búsqueda.
%~ 
%~ \end{itemize}
%~ 








%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Proteómica dirigida. SRM}
%\addcontentsline{toc}{section}{Proteómica dirigida. SRM/MRM}
\label{cap1:sec:Proteomica dirigida. SRM}

%\todo{Mirar paper Picotti & Aebersold SRM proteomics: worfkflows y pitfalls como referencia para las secciones}

La proteómica \textit{shotgun}, cuyo objetivo es detectar
la mayor cantidad posible de proteínas en una muestra, se denomina
en ocasiones por ello, proteómica \textit{de descubrimiento}. 
En esto, esencialmente, la \emph{proteómica dirigida} se distingue de las 
técnicas de \textit{shotgun}, en el objetivo. Esta metodología no pretende identificar
una gran cantidad de proteínas diferentes en la muestra, sino que intenta 
identificar y, opcionalmente también cuantificar, una proteína o un grupo
de proteínas de interés seleccionadas \textit{a priori}.
De ahí el nombre proteómica \textit{dirigida}. A diferencia de
las técnicas \textit{shotgun} donde los \textit{n} precursores más abundantes
son seleccionados para ser fragmentados en una adquisición dependiente 
de datos (DDA), en la proteómica dirigida la adquisición es denominada 
\ac{DIA}

La técnica que se utiliza para llevar a cabo experimentos de proteómica
dirigida se denomina \ac{SRM} o también,
frecuentemente utilizado como sinónimo, \ac{MRM}.

La proteómica dirigida, basada en técnicas SRM, desde hace unos años está 
emergiendo y popularizándose como un complemento ideal de las técnicas 
de \textit{shotgun}. Las técnicas SRM proporcionan unas propiedades muy interesantes en
experimentos en que se requiere que un grupo de proteínas, por ejemplo biomarcadores o
proteínas constituyentes de una red o ruta particular, sean detectadas
y cuantificadas de una forma precisa y reproducible en diferentes muestras
que se quiere comparar.

Originalmente desarrollada para detectar y cuantificar
pequeñas moléculas como metabolitos o fármacos, las
primeras aplicaciones de SRM al campo de la proteómica comenzaron en 
2003 \citep{Gerber2003}, 2004 \citep{Kuhn2004}.

El principio fundamental en el que se basa la técnica SRM consiste en
aprovechar la capacidad de espectrómetros de masas de tipo triple cuadrupolo
para actuar como filtros de masas de analitos a dos niveles consecutivos, 
el de un péptido precursor, y el de los fragmentos que se generan tras ser éste
fragmentado. Los péptidos son monitorizados usando \textit{transiciones}, conjuntos
de valores \mz de un precursor y valores \mz de productos correspondientes.
Este doble filtro es, idealmente, muy específico del
péptido, y por extensión, de la proteína originaria. Por eso es esencial utilizar
péptidos \textit{proteotípicos}, aquellos cuya
secuencia del péptido es única y específica de la proteína a la que pertenece.


La señal que se genera en el instrumento al medir la cantidad
de estos fragmentos, junto con la información del tiempo de retención
cromatográfica permite reconstruir un pico de elución en el que
se puede observar que los fragmentos co-eluyen en el tiempo de retención
del péptido monitorizado. (Figura\ref{fig:esquema_srm})

Sin embargo, en ocasiones a pesar de usar péptidos proteotípicos y comprobar
que los fragmentos coeluyen, puede ocurrir que las señales correspondan a otro
péptido distinto al que se está monitorizando. Para aumentar la confianza
en la identificación se puede disparar un espectro MS/MS a partir del péptido
monitorizado y confirmar su identidad (MIDAS, \textit{MRM Initiated Detection And Sequencing})
También se pueden añadir a la muestra versiones sintéticos de los péptidos que se monitorizan,
con un marcaje isotópico que permitan ubicar el tiempo de retención exacto.

\figura{Vectorial/esquema_srm}{width=.99\textwidth}{fig:esquema_srm}%
{Adquisición y reconstrucción de la señal en un experimento SRM} 



%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Repositorios públicos de proteómica \textit{online}}
%\addcontentsline{toc}{section}{Repositorios publicos de Proteómica shotgun y dirigida}
\label{cap1:sec:Repositorios publicos de Proteomica online}

Los resultados generados en experimentos de proteómica han de ser 
convenientemente mostrados y compartidos con la comunidad científica.
Algunos de los repositorios más populares que almacenan y permiten visualzar
resultados de experimentos de proteómica son PRIDE y PeptideAtlas.

\subsection{PRIDE}
\label{PRIDE}
La base de datos \ac{PRIDE}, creada en el Instituto Bioinformático Europeo en
Inglaterra \citep{Martens2005} es el repositorio más extenso de datos 
de espectrometría de masas. Almacena los resultados originales enviados 
por los investigadores usando para ello su propio formato PRIDE XML.
Además se han desarrollado herramientas que facilitan la creación y el
envío de los resultados en este formato.


\subsection{PeptideAtlas}
\label{PeptideAtlas}
El proyecto PeptideAtlas surgió en 2005 en el Instituto de Biología de
Sistemas, Seattle, Washington. \citep{Desiere2006}. 
A diferencia de PRIDE, donde los resultados enviados no son reanalizados
de ninguna forma sino que se mantienen como los usuarios los enviaron,
PeptideAtlas sí cuenta con un flujo de validación de los resultados. Este
análisis, denominado \ac{TPP} \citep{Deutsch2010c} emplea secuencialemente
los programas descritos PeptideProphet, ProteinProphet y iProphet principalmente,
para asegurar la calidad y robustez de los datos de identificaciones
mostrados. Inicialmente contaba con datos de proteínas humanas y 
posteriormente un gran número de especies se han incorporado.
El trabajo titulado \emph{A Candida albicans PeptideAtlas} \citep{Vialas2013}
forma parte del proyecto desde 2012.




%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{Formatos de archivos usados en espectrometría de masas y proteómica}
%\addcontentsline{toc}{section}{Formatos de archivos usados en espectrometría de masas y Proteómica}
%\label{cap1:sec:Formatos en Proteómica}

En el proceso de análisis de datos que sigue a la adquisición 
experimental de espectros se requiere un uso intensivo de \textit{software},
desde la asignación de secuencias peptídicas a los espectros hasta la
elaboración de listas de proteínas identificadas y evaluación estadística
de los resultados.
Existe una gran variedad de este tipo de programas, que sirven de apoyo
a cada uno de estos pasos en el proceso de análisis

En términos muy generales se puede distinguir \textit{software} abierto,
que la comunidad bioinformática ha desarrollado en respuesta a las necesidades
de compartir, inspeccionar y generar ficheros sin las restricciones que imponen
las licencias; y \textit{software} privativo desarrollado \textit{ad hoc} por las 
compañías fabricantes de espectrómetros de masas para sus instrumentos.
En este sentido la iniciativa HUPO-PSI ha adquirido un papel muy importante
en la elaboración y difusión de formatos abiertos que puedan servir de 
estándar para toda la comunidad.

%La iniciativa HUPO-PSI tiene un papel muy importante en la elaboración
%y adopción de formatos abiertos que puedan servir de estándar para toda
%la comunidad. En esta tarea de estandarización están implicados representantes
%de las compañías fabricantes de equipos, editores de revistas, y desarrolladores
%de código del ámbito académico para revisar y proporcionar formatos que 
%recojan toda la información necesaria (MIAPE)

En una clasificacion más precisa, estos formatos pueden clasificarse en función
de la etapa del análisis al que sirven de ayuda.

\figuraEx{Vectorial/formats}{width=.75\textwidth}{fig:formats_in_proteomics}%
{Visión general de formatos comúmente usados en cada etapa de un experimento de proteómica.
Los formatos adoptados como estándar por HUPO-PSI contienen el símbolo $\Psi$}
{Formatos de archivos en proteómica}


\begin{itemize}

\item \emph{Formatos que recogen la salida de los espectrómetros de masas}

%~ Los datos perfil permiten ver la forma de los picos del espectro de masas. %Copiado de TSQ_Series_Hardware_es.pdf
%~ Cada unidad de masa atómica se divide en muchos intervalos de muestreo. %Copiado de TSQ_Series_Hardware_es.pdf
%~ La intensidad de la corriente iónica se determina en cada uno de los %Copiado de TSQ_Series_Hardware_es.pdf
%~ intervalos de muestreo. Este tipo de datos muestra la intensidad en  %Copiado de TSQ_Series_Hardware_es.pdf
%~ cada uno de los intervalos de muestreo con las intensidades %Copiado de TSQ_Series_Hardware_es.pdf
%~ conectadas por una línea continua. %Copiado de TSQ_Series_Hardware_es.pdf
%En otras ocasiones, con el 
%objetivo de ahorrar espacio, solo se registra la señal cuando se supera un
%cierto umbral de intensidad que discierne la señal real del ruido. Este tipo de
%espectros es similar a los adquiridos en modo continuo pero los valles
%entre picos no quedan registrados.

Este es un tipo de formatos muy diverso. 
Depende básicamente, de la forma en que se detectan y recogen los espectros. %a lo mejor puedo recortar esto 
Cuando la frecuencia en que %ver File Formats commonly used in MS . Deutsch E %a lo mejor puedo recortar esto
se escanea cada fragmento es superior a la resolución del instrumento la %a lo mejor puedo recortar esto
señal se registra como picos con una forma y anchura precisas. Este tipo %a lo mejor puedo recortar esto
de adquisición es el \emph{modo continuo o perfil}. %a lo mejor puedo recortar esto
Los instrumentos registran los espectros en modo continuo de forma predeterminada, %a lo mejor puedo recortar esto
pero frecuentemente son sometidos %a lo mejor puedo recortar esto
a un procesamiento por un algoritmo que extrae los picos detectados como %a lo mejor puedo recortar esto
parejas de valores \mz e intensidad. Esto se denomina adquisición de %a lo mejor puedo recortar esto
\emph{datos centroide}. %a lo mejor puedo recortar esto
%~ muestran el espectro de masas como un gráfico de barras y suman las %Copiado de TSQ_Series_Hardware_es.pdf
%~ intensidades de cada conjunto de varios intervalos de muestreo. %Copiado de TSQ_Series_Hardware_es.pdf
%~ Esta suma se muestra frente al centrado integral de masa de los intervalos %Copiado de TSQ_Series_Hardware_es.pdf
%~ de muestreo. %Copiado de TSQ_Series_Hardware_es.pdf

Entre los formatos desarrollados por los fabricantes podemos encontrar
aquellos para los que toda la información de los espectros se encuentra 
en un solo archivo, aquellos para los que la información se divide en un 
par de archivos y aquellos con múltiples archivos para cada adquisición de espectros.
Así, para los instrumentos \textit{Thermo Scientific} el formato es del primer tipo, 
toda la información es codificada en archivos con extensión .RAW (datos perfil 
o centroide a elección). Los instrumentos AB-Sciex en su mayoría
(excepto los TOF-TOF) pueden generar archivos del segundo tipo, en pares
donde un archivo con extension \textit{.wiff} contiene los metadatos
y un archivo \textit{.wiff.scan} contiene los espectros. Por último, para
algunos instrumentos de Waters y Agilent, se obtienen múltiples archivos
agrupados en carpetas con extensión \textit{.d} o \textit{.raw}.

Sin embargo, el hecho de que estos formatos sean codificados en binario
junto con la disponibilidad de las librerías de lectura
proporcionadas por los fabricantes restringida únicamente al sistema operativo
MS Windows frenó el desarrollo de nuevas herramientas de lectura y 
manipulación de este tipo de archivos.
En ese contexto, aparecieron los primeros formatos de texto (XML) para codificar
toda la información de salida de MS, mzXML \citep{Pedrioli2004} y mzData 
que posteriormente fueron unificados en el estándar HUPO-PSI mzML \citep{Deutsch2010d}.

Por último, una solución intermedia, ideada previamente a la aparición
de los formatos basados en XML descritos, es la creación de ficheros
de texto simples con una simple lista de los picos obtenidos para cada ión
precursor y sus fragmentos. Los formatos de archivo con extensión \textit{.pkl}
\textit{.dta} o \textit{.ms2} contienen espectros independientes en cada
fichero, los \textit{.MGF} pueden contener múltiples espectros en un solo fichero.

\item \emph{Formatos que recogen el resultado de las búsquedas}

Este tipo de formatos se encuentra generalmente muy ligado al \textit{software}
empleado para generar los resultados, es decir el motor de búsqueda.
SEQUEST, comenzó usando los formatos \textit{.out} y \textit{.SQT} pero
posteriormente ha desarrollado los \textit{.SRF} y \textit{.MSF}.
X!Tandem y OMSSA generan archivos basados en XML \textit{.tandem} y    
\textit{.omx} respectivamente.

Para independizar el motor de búsqueda usado del formato obtenido se 
creó el formato \textit{.pepXML} que además permite el análisis
por las herramientas de \ac{TPP}. \textit{pepXML}, cuya unidad de 
información básica es el PSM, es el formato que lee y escribe
PeptideProphet, para ProteinProphet, se creó \textit{.protXML}, que 
contiene la lista de proteínas y sus péptidos asignados.

Sin embargo, de nuevo \textit{pepXML} y \textit{protXML}, 
aunque muy populares, también estaban ligados al flujo de análisis de TPP.
Y de nuevo, HUPO-PSI ideó un nuevo formato estándar para recoger toda 
información derivada del resultado de búsquedas y análisis
independientemente de su origen, el mzIdentML \citep{Jones2012}.
Además, HUPO-PSI también ha desarrollado mzTab, una versión alternativa
simplificada que no se basa en XML sino en texto separado por tabulador.
 

\item \emph{Formatos que almacenan bibliotecas de espectros}

Los motores de búsqueda que usan bibliotecas de espectros, como SpectraST
(parte de TPP) \citep{Lam2007} requieren generalmente un formato 
que contenga espectros consenso, una combinación de los espectros y el péptido
que se les ha asignado, así como otras anotaciones y metadatos.
El \ac{NIST}
distribuye bibliotecas de espectros en formato \textit{.msp}. SpectraST
produce el formato \textit{.splib}; y X!Hunter y Bibliospec \textit{ASL}
y \textit{.blib} respectivamente.


\item \emph{Formatos que almacenan secuencias}

Los motores de búsqueda basados en secuencia requieren que se les 
suministren secuencias de cada proteína (y también, para cada una de ellas
su correspondiente secuencia señuelo). Para ello el tipo de formato más
usado es el celebérrimo FASTA. Sin embargo no es el único, HUPO-PSI
ha creado el formato PEFF, que mejora a FASTA añadiendo reglas sobre 
cómo ha de expresarse la cabecera de cada secuencia. Esta sintaxis definida
facilita la tarea al \textit{software} que lee los ficheros.

\item \emph{Formatos específicos para proteómica dirigida}

En proteómica dirigida, podemos encontrar dos tipos de formatos. 
Entre los que se usan como fuente de entrada de información,
para indicar al espectrómetro las listas de transiciones, 
es decir, que precursores y fragmentos ha de monitorizar, los más 
empleados son .\textit{sky}, empleado por el programa Skyline; y el 
estándar HUPO-PSI \textit{TraML} \citep{Deutsch2012a}.
Para los resultados de análisis por SRM, el programa Skyline usa 
su propio formato, \textit{.skyd}, basado en XML y otros programas
como mProphet \citep{Reiter2011a} usan sus propios formatos de texto 
separado por tabulador.


\end{itemize}





%-------------------------------------------------------------------
%-------------------------------------------------------------------

%\phantomsection
\section{\textit{Candida albicans} como organismo modelo}
%\addcontentsline{toc}{section}{Candida albicans como organismo modelo}
\label{cap1:sec:Candida albicans como organismo modelo}


\textit{C. albicans} es un hongo patógeno oportunista que se encuentra comúnmente
como residente comensal, inocuo, en las mucosas gastrointestinal y urogenital en
un alto porcentaje de la población \citep{Calderone2012}. Sin embargo, su cualidad de patógeno
oportunista implica que, en ocasiones, propiciadas generalmente por un
sistema inmune debilitado en el hospedador, puede proliferar y diseminarse
provocando infecciones, candidiasis, de gravedad variable, desde afecciones 
mucocutáneas leves hasta infecciones sistémicas severas que pueden incluso llegar a ser letales.
En Estados Unidos especies del género \textit{Candida} suponen la cuarta
causa más común de infecciones nosocomiales con tasas de mortalidad de hasta
el 50\% en el caso de infecciones sistémicas \citep{Pfaller2010}.
%Mayer Hube 2013 C. albicans pathogenicity mechanisms:
Los principales factores de virulencia con los que cuenta \textit{C. albicans}
para proliferar y diseminarse causando infecciones son su polimorfismo,
su capacidad de producir adhesinas e invasinas, y la formación de biopelículas \citep{Mayer2013}. 

El polimorfismo consiste en la capacidad
de transformar su morfología. Las morfologías más comunes 
(además de otras como las pseudohifas y las clamidosporas) 
son la clásica forma ovalada levaduriforme,
adecuada para la diseminación a través de los vasos sanguíneos, y los
filamentos o hifas que permiten penetrar e invadir tejidos \citep{Berman2002, Jacobsen2012}.

\figuraEx{Vectorial/candida_vs_macrophage}{width=.80\textwidth}{fig:candida_vs_macrophage}%
{La población comensal de células de \textit{C. albicans}
 y células del sistema inmune como macrófagos, presentes en las mucosas
 de los tractos gastrointestinal y genito-urinario se encuentran en un 
 \textit{status} de equilibrio en condiciones normales.}
{Equilibrio entre \textit{Candida albicans} y células del sistema inmune}



La producción de adhesinas, proteínas especializadas en la adhesión
a la superficies abióticas o de otras células es otro importante factor de virulencia.
Las aglutininas de la familia ALS que incluyen proteinas con anclaje GPI
como Als3 \citep{Phan2007, DeGroot2013} y otras como la también anclada mediante GPI y asociada
a hifas Hwp1 \citep{Sundstrom2002} son algunas de las adhesinas más estudiadas.

La formación de biopelículas sobre sustratos abióticos como catéteres o
prótesis dentales o sobre la superficie celular en mucosas también supone
un factor de virulencia crítico. Se ha descrito que biopelículas maduras
adquieren una mayor resistencia a antifúngicos y a la acción del sistema
inmune del hospedador en comparación con células planctónicas \citep{Fanning2012}.


%Otros factores de virulencia son Mirar Mayer Hube 2013 C. albicans pathogenicity mechanisms

Desde el punto de vista de la proteómica, se han realizado muy diversos
estudios usando el modelo de \textit{C. albicans}. En este sentido
los ensayos proteómicos se han enfocado principalmente en el estudio
de los rasgos patógenos. Existen trabajos enfocados al estudio del proteoma 
de la pared celular \citep{Castillo2008}, estudios de proteómica de los factores de 
virulencia \citep{Pitarch2006}, de la respuesta serológica \citep{Pitarch2009}
y también estudios sobre la resistencia a antifúngicos \citep{Hoehamer2010}.


